<div align="center">

<!-- <!-- <h1 style="color: #33A6B8; font-family: Helvetica"> OmniLMM </h1> -->

<img src="./assets/minicpmv-omnilmm.png" width="400em" ></img> 

**æ€§èƒ½é¢†å…ˆä¸”éƒ¨ç½²é«˜æ•ˆçš„å¤šæ¨¡æ€å¤§æ¨¡å‹**

  <strong>ä¸­æ–‡ |
  [English](./README_en.md)</strong>

<p align="center">
  MiniCPM-V 2.0  <a href="https://huggingface.co/openbmb/MiniCPM-V-2/">ğŸ¤—</a> <a href="http://120.92.209.146:80/">ğŸ¤–</a> |
  OmniLMM-12B <a href="https://huggingface.co/openbmb/OmniLMM-12B/">ğŸ¤—</a> <a href="http://120.92.209.146:8081">ğŸ¤–</a> |
  <a href="https://openbmb.vercel.app/minicpm-v-2">MiniCPM-V 2.0 æŠ€æœ¯åšå®¢</a>
</p>

</div>


**MiniCPM-V**å’Œ**OmniLMM** æ˜¯é¢å‘å›¾æ–‡ç†è§£çš„å¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ã€‚è¯¥ç³»åˆ—æ¨¡å‹æ¥å—å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œå¹¶æä¾›é«˜è´¨é‡çš„æ–‡æœ¬è¾“å‡ºã€‚æˆ‘ä»¬å‘å¸ƒäº†ä¸¤ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°**é¢†å…ˆçš„æ€§èƒ½å’Œé«˜æ•ˆçš„éƒ¨ç½²**ï¼š

- **MiniCPM-V 2.8B**ï¼šå¯åœ¨ç»ˆç«¯è®¾å¤‡ä¸Šéƒ¨ç½²çš„å…ˆè¿›å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚æœ€æ–°å‘å¸ƒçš„ MiniCPM-V 2.0 å¯ä»¥æ¥å— 180 ä¸‡åƒç´ çš„ä»»æ„é•¿å®½æ¯”å›¾åƒè¾“å…¥ï¼Œå®ç°äº†å’Œ Gemini Pro ç›¸è¿‘çš„åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä»¥åŠå’Œ GPT-4V ç›¸åŒ¹çš„ä½å¹»è§‰ç‡ã€‚

- **OmniLMM-12B**ï¼šç›¸æ¯”åŒè§„æ¨¡å…¶ä»–æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å…·æœ‰é¢†å…ˆæ€§èƒ½ï¼Œå®ç°äº†ç›¸æ¯” GPT-4V æ›´ä½çš„å¹»è§‰ç‡ã€‚


## æ›´æ–°æ—¥å¿— <!-- omit in toc -->

* [2024.04.17] MiniCPM-V 2.0 ç°åœ¨æ”¯æŒç”¨æˆ·éƒ¨ç½²æœ¬åœ° [WebUI Demo](#webui-demo) äº†ï¼Œæ¬¢è¿è¯•ç”¨!
* [2024.04.15] MiniCPM-V 2.0 ç°åœ¨æ”¯æŒ SWIFT æ¡†æ¶ä¸‹çš„ [å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-v-2æœ€ä½³å®è·µ.md) äº†ï¼Œæ”¯æŒæµå¼è¾“å‡º!
* [2024.04.12] æˆ‘ä»¬å¼€æºäº† MiniCPM-V 2.0ï¼Œè¯¥æ¨¡å‹åˆ·æ–°äº† OCRBench å¼€æºæ¨¡å‹æœ€ä½³æˆç»©ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Šæ¯”è‚© Gemini Proï¼ŒåŒæ—¶è¿˜åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ <a href="https://rank.opencompass.org.cn/leaderboard-multimodal">OpenCompass</a> æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 10Bã€CogVLM-Chat 17B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼ç‚¹å‡»<a href="https://openbmb.vercel.app/minicpm-v-2">è¿™é‡Œ</a>æŸ¥çœ‹ MiniCPM-V 2.0 æŠ€æœ¯åšå®¢ã€‚
* [2024.03.14] MiniCPM-V ç°åœ¨æ”¯æŒ SWIFT æ¡†æ¶ä¸‹çš„[å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-væœ€ä½³å®è·µ.md)äº†ï¼Œæ„Ÿè°¢ [Jintao](https://github.com/Jintao-Huang) çš„è´¡çŒ®ï¼
* [2024.03.01] MiniCPM-V ç°åœ¨æ”¯æŒåœ¨ Mac ç”µè„‘ä¸Šè¿›è¡Œéƒ¨ç½²ï¼
* [2024.02.01] æˆ‘ä»¬å¼€æºäº† MiniCPM-V å’Œ OmniLMM-12Bï¼Œåˆ†åˆ«å¯ä»¥æ”¯æŒé«˜æ•ˆçš„ç«¯ä¾§éƒ¨ç½²å’ŒåŒè§„æ¨¡é¢†å…ˆçš„å¤šæ¨¡æ€èƒ½åŠ›ï¼


## ç›®å½• <!-- omit in toc -->


- [MiniCPM-V 2.8B](#minicpm-v-28b)
- [OmniLMM-12B](#omnilmm-12b)
- [Online Demo](#online-demo)
- [å®‰è£…](#å®‰è£…)
- [æ¨ç†](#æ¨ç†)
  - [æ¨¡å‹åº“](#æ¨¡å‹åº“)
  - [å¤šè½®å¯¹è¯](#å¤šè½®å¯¹è¯)
  - [Mac æ¨ç†](#mac-æ¨ç†)
  - [æ‰‹æœºç«¯éƒ¨ç½²](#æ‰‹æœºç«¯éƒ¨ç½²)
  - [æœ¬åœ°WebUI Demoéƒ¨ç½²](#æœ¬åœ°webui-demoéƒ¨ç½²)
- [å¾®è°ƒ](#å¾®è°ƒ)
- [æœªæ¥è®¡åˆ’](#æœªæ¥è®¡åˆ’)
- [å¼•ç”¨](#å¼•ç”¨)


## MiniCPM-V 2.8B

**MiniCPM-V 2.8B**å¯ä»¥é«˜æ•ˆéƒ¨ç½²åˆ°ç»ˆç«¯è®¾å¤‡ã€‚è¯¥æ¨¡å‹åŸºäº SigLip-400M å’Œ [MiniCPM-2.4B](https://github.com/OpenBMB/MiniCPM/)æ„å»ºï¼Œé€šè¿‡perceiver resamplerè¿æ¥ã€‚æœ€æ–°å‘å¸ƒçš„ MiniCPM-V 2.0 çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- ğŸ”¥ **ä¼˜ç§€çš„æ€§èƒ½ã€‚**

  MiniCPM-V 2.0 åœ¨å¤šä¸ªæµ‹è¯•åŸºå‡†ï¼ˆå¦‚ OCRBench, TextVQA, MME, MMB, MathVista ç­‰ï¼‰ä¸­å®ç°äº† 7B ä»¥ä¸‹æ¨¡å‹çš„**æœ€ä½³æ€§èƒ½**ã€‚**åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ OpenCompass æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 9.6Bã€CogVLM-Chat 17.4B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹**ã€‚MiniCPM-V 2.0 è¿˜å±•ç°å‡º**é¢†å…ˆçš„ OCR èƒ½åŠ›**ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Š**æ¥è¿‘ Gemini Pro**ï¼ŒOCRBench å¾—åˆ†è¾¾åˆ°**å¼€æºæ¨¡å‹ç¬¬ä¸€**ã€‚
  

- ğŸ† **å¯ä¿¡è¡Œä¸ºã€‚** 

  å¤šæ¨¡æ€å¤§æ¨¡å‹æ·±å—å¹»è§‰é—®é¢˜å›°æ‰°ï¼Œæ¨¡å‹ç»å¸¸ç”Ÿæˆå’Œå›¾åƒä¸­çš„äº‹å®ä¸ç¬¦çš„æ–‡æœ¬ã€‚MiniCPM-V 2.0 æ˜¯ **ç¬¬ä¸€ä¸ªé€šè¿‡å¤šæ¨¡æ€ RLHF å¯¹é½çš„ç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ˆå€ŸåŠ© [RLHF-V](https://rlhf-v.github.io/) [CVPR'24] ç³»åˆ—æŠ€æœ¯ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ [Object HalBench](https://arxiv.org/abs/2312.00849) è¾¾åˆ°**å’Œ GPT-4V ç›¸ä»¿**çš„æ€§èƒ½ã€‚


- ğŸŒŸ **é«˜æ¸…å›¾åƒé«˜æ•ˆç¼–ç ã€‚**

  MiniCPM-V 2.0 å¯ä»¥æ¥å— **180 ä¸‡åƒç´ çš„ä»»æ„é•¿å®½æ¯”å›¾åƒè¾“å…¥**ï¼ˆåŸºäºæœ€æ–°çš„[LLaVA-UHD](https://arxiv.org/pdf/2403.11703.pdf) æŠ€æœ¯ï¼‰ï¼Œè¿™ä½¿å¾—æ¨¡å‹å¯ä»¥æ„ŸçŸ¥åˆ°å°ç‰©ä½“ã€å¯†é›†æ–‡å­—ç­‰æ›´åŠ ç»†ç²’åº¦çš„è§†è§‰ä¿¡æ¯ã€‚ 


- âš¡ï¸ **é«˜æ•ˆéƒ¨ç½²ã€‚**

  MiniCPM-V 2.0 å¯ä»¥**é«˜æ•ˆéƒ¨ç½²åœ¨å¤§å¤šæ•°æ¶ˆè´¹çº§æ˜¾å¡å’Œä¸ªäººç”µè„‘ä¸Š**ï¼ŒåŒ…æ‹¬**ç§»åŠ¨æ‰‹æœºç­‰ç»ˆç«¯è®¾å¤‡**ã€‚åœ¨è§†è§‰ç¼–ç æ–¹é¢ï¼Œæˆ‘ä»¬é€šè¿‡perceiver resamplerå°†å›¾åƒè¡¨ç¤ºå‹ç¼©ä¸ºæ›´å°‘çš„ tokenã€‚è¿™ä½¿å¾— MiniCPM-V 2.0 å³ä¾¿æ˜¯**é¢å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä¹Ÿèƒ½å ç”¨è¾ƒä½çš„å­˜å‚¨å¹¶å±•ç°ä¼˜ç§€çš„æ¨ç†é€Ÿåº¦**ã€‚

- ğŸ™Œ **åŒè¯­æ”¯æŒã€‚**

  MiniCPM-V 2.0 **æä¾›é¢†å…ˆçš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€èƒ½åŠ›æ”¯æŒ**ã€‚
  è¯¥èƒ½åŠ›é€šè¿‡ [VisCPM](https://arxiv.org/abs/2308.12038) [ICLR'24] è®ºæ–‡ä¸­æå‡ºçš„å¤šæ¨¡æ€èƒ½åŠ›çš„è·¨è¯­è¨€æ³›åŒ–æŠ€æœ¯å®ç°ã€‚

### æ€§èƒ½è¯„ä¼° <!-- omit in toc -->

<div align="center">
    <img src=assets/minicpmv-2-peformance.png width=66% />
</div>
<details>
<summary>TextVQA, DocVQA, OCRBench, OpenCompass, MME, MMBench, MMMU, MathVista, LLaVA Bench, Object HalBench ä¸Šçš„è¯¦ç»†è¯„æµ‹ç»“æœã€‚ </summary>
<div align="center">

<table style="margin: 0px auto;">
<thead>
  <tr>
    <th align="left">Model</th>
    <th>Size</th>
    <th>TextVQA val</th>
    <th>DocVQA test</th>
    <th>OCRBench</th>
    <th>OpenCompass</th>
    <th nowrap="nowrap" >MME</th>
    <th>MMB dev(en)</th>
    <th>MMB dev(zh)</th>
    <th>MMMU val</th>
    <th>MathVista</th>
    <th>LLaVA Bench</th>
    <th nowrap="nowrap">Object HalBench</th>
  </tr>
</thead>
<tbody align="center">
  <tr>
    <td colspan="12" align="left"><strong>Proprietary models</strong></td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left">Gemini Pro Vision</td>
    <td>- </td>
    <td>74.6</td>
    <td>88.1</td>
    <td>680</td>
    <td>63.8</td>
    <td>2148.9</td>
    <td>75.2</td>
    <td>74.0</td>
    <td>48.9</td>
    <td>45.8</td>
    <td>79.9</td>
    <td>- </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left">GPT-4V</td>
    <td>- </td>
    <td>78.0</td>
    <td>88.4</td>
    <td>645</td>
    <td>63.2</td>
    <td>1771.5</td>
    <td>75.1</td>
    <td>75.0</td>
    <td>53.8</td>
    <td>47.8</td>
    <td>93.1</td>
    <td>86.4 / 92.7</td>
  </tr>
  <tr>
    <td colspan="12" align="left"><strong>Open-source models 6B~34B</strong></td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >Yi-VL-6B</td>
    <td align="right" >6.7B</td>
    <td>45.5*</td>
    <td>17.1*</td>
    <td>290</td>
    <td>49.3</td>
    <td>1915.1 </td>
    <td>68.6 </td>
    <td>68.3 </td>
    <td>40.3 </td>
    <td>28.8 </td>
    <td>51.9 </td>
    <td>- </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >Qwen-VL-Chat</td>
    <td align="right" >9.6B</td>
    <td>61.5</td>
    <td>62.6</td>
    <td>488 </td>
    <td>52.1 </td>
    <td>1860.0 </td>
    <td>60.6 </td>
    <td>56.7 </td>
    <td>37.0 </td>
    <td>33.8 </td>
    <td>67.7 </td>
    <td>56.2 / 80.0</td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" >Yi-VL-34B</td>
    <td align="right" >34B</td>
    <td>43.4*</td>
    <td>16.9*</td>
    <td>290</td>
    <td>52.6 </td>
    <td>2050.2</td>
    <td>71.1</td>
    <td>71.4</td>
    <td>45.1</td>
    <td>30.7</td>
    <td>62.3</td>
    <td>- </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >DeepSeek-VL-7B</td>
    <td align="right" >7.3B</td>
    <td>64.7*</td>
    <td>47.0* </td>
    <td>435</td>
    <td>55.6 </td>
    <td>1765.4 </td>
    <td>74.1 </td>
    <td>72.8 </td>
    <td>38.3 </td>
    <td>36.8</td>
    <td>77.8 </td>
    <td>- </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >TextMonkey</td>
    <td align="right" >9.7B</td>
    <td>64.3</td>
    <td>66.7 </td>
    <td>558</td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
    <td>-</td>
    <td>- </td>
    <td>- </td>
  </tr>
    <tr>
    <td  nowrap="nowrap" align="left" >CogVLM-Chat</td>
    <td align="right" >17.4B</td>
    <td>70.4</td>
    <td>33.3*</td>
    <td>590 </td>
    <td>52.5 </td>
    <td>1736.6 </td>
    <td>63.7 </td>
    <td>53.8 </td>
    <td>37.3 </td>
    <td>34.7 </td>
    <td>73.9 </td>
    <td>73.6 / 87.4 </td>
  </tr>
  <tr>
    <td colspan="12" align="left"><strong>Open-source models 1B~3B </strong></td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >DeepSeek-VL-1.3B</td>
    <td align="right" >1.7B</td>
    <td>58.4*</td>
    <td>37.9*</td>
    <td>413</td>
    <td>46.0 </td>
    <td>1531.6 </td>
    <td>64.0 </td>
    <td>61.2 </td>
    <td>33.8 </td>
    <td>29.4 </td>
    <td>51.1 </td>
    <td>- </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >MobileVLM V2</td>
    <td align="right" >3.1B</td>
    <td>57.5</td>
    <td>19.4*</td>
    <td>-</td>
    <td>-</td>
    <td>1440.5(P) </td>
    <td>63.2 </td>
    <td>-</td>
    <td>-</td>
    <td>-</td>
    <td>-</td>
    <td>-</td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >Mini-Gemini</td>
    <td align="right" >2.2B</td>
    <td>56.2</td>
    <td>34.2*</td>
    <td>-</td>
    <td>-</td>
    <td>1653.0 </td>
    <td>59.8 </td>
    <td>- </td>
    <td>31.7 </td>
    <td>-</td>
    <td>- </td>
    <td>- </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" >MiniCPM-V</td>
    <td align="right" >2.8B </td>
    <td>60.6</td>
    <td>38.2 </td>
    <td>366</td>
    <td>47.6</td>
    <td>1650.2 </td>
    <td>67.9 </td>
    <td>65.3 </td>
    <td><strong>38.3</strong></td>
    <td>28.9</td>
    <td>51.3 </td>
    <td>78.4 / 88.5 </td>
  </tr>
  <tr>
    <td  nowrap="nowrap" align="left" ><strong>MiniCPM-V 2.0</strong></td>
    <td align="right" >2.8B </td>
    <td><strong>74.1</strong></td>
    <td><strong>71.9</strong> </td>
    <td><strong>605</strong></td>
    <td><strong>55.0</strong></td>
    <td><strong>1808.6</strong> </td>
    <td><strong>69.6</strong> </td>
    <td><strong>68.1</strong> </td>
    <td>38.2 </td>
    <td><strong>38.7</strong></td>
    <td><strong>69.2</strong> </td>
    <td><strong>85.5 / 92.2 </strong></td>
  </tr>
</tbody>
</table>

</div>
* æˆ‘ä»¬è‡ªå·±è¯„æµ‹äº†æ­£å¼å¼€æºçš„æ¨¡å‹æƒé‡ã€‚

</details>

### å…¸å‹ç¤ºä¾‹ <!-- omit in toc -->


<table align="center">
    <p align="center">
      <img src="assets/minicpmv2-cases_2.png" width=95%/>
    </p>
</table>

æˆ‘ä»¬å°† MiniCPM-V 2.0 éƒ¨ç½²åœ¨å°ç±³ 14 Pro ä¸Šï¼Œå¹¶å½•åˆ¶äº†ä»¥ä¸‹æ¼”ç¤ºè§†é¢‘ï¼Œæœªç»ä»»ä½•è§†é¢‘å‰ªè¾‘ã€‚

<table align="center">
    <p align="center">
      <img src="assets/gif_cases/station.gif" width=36%/>
      <img src="assets/gif_cases/london_car.gif" width=36%/>
    </p>
</table>

### MiniCPM-V 1.0 <!-- omit in toc -->

è¯·å‚è€ƒ[è¿™é‡Œ](./minicpm_v1.md)äº†è§£ MiniCPM-V 1.0 çš„ä¿¡æ¯å’Œä½¿ç”¨æ•™ç¨‹ã€‚


## OmniLMM-12B
**OmniLMM-12B** æ˜¯å½“å‰ç³»åˆ—ä¸­æ€§èƒ½æœ€ä½³çš„ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹åŸºäºEVA02-5Bå’ŒZephyr-7B-Î²åˆå§‹åŒ–æ„å»ºï¼Œå¹¶ä½¿ç”¨perceiver resamplerè¿æ¥ï¼Œé‡‡ç”¨äº†è¯¾ç¨‹å­¦ä¹ çš„æ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹å…·æœ‰ä¸‰ä¸ªç‰¹ç‚¹ï¼š

- ğŸ”¥ **æ€§èƒ½é¢†å…ˆã€‚**

  OmniLMM-12B ç›¸æ¯”å…¶ä»–åŒè§„æ¨¡æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—**é¢†å…ˆçš„æ€§èƒ½**ï¼ˆåŒ…æ‹¬ MMEã€MMBenchã€SEED-Bench ç­‰ï¼‰ï¼Œæ¨¡å‹æŒæ¡äº†è¾ƒä¸ºä¸°å¯Œçš„å¤šæ¨¡æ€ä¸–ç•ŒçŸ¥è¯†ã€‚

- ğŸ† **è¡Œä¸ºå¯ä¿¡ã€‚**

  å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜å¤‡å—å…³æ³¨ï¼Œæ¨¡å‹ç»å¸¸ç”Ÿæˆå’Œå›¾åƒä¸­çš„äº‹å®ä¸ç¬¦çš„æ–‡æœ¬ï¼ˆä¾‹å¦‚ï¼Œç¡®ä¿¡åœ°æè¿°å›¾ç‰‡ä¸­å¹¶ä¸å­˜åœ¨çš„ç‰©ä½“ï¼‰ã€‚OmniLMM-12Bæ˜¯ **ç¬¬ä¸€ä¸ªé€šè¿‡å¤šæ¨¡æ€ RLHF å¯¹é½çš„ç»¼åˆèƒ½åŠ›ä¼˜ç§€çš„å¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ˆå€ŸåŠ© [RLHF-V](https://rlhf-v.github.io/) [CVPR'24] ç³»åˆ—æŠ€æœ¯ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ [MMHal-Bench](https://huggingface.co/datasets/Shengcao1006/MMHal-Bench) å¹»è§‰è¯„æµ‹åŸºå‡†ä¸Šè¾¾åˆ°**å¼€æºæ¨¡å‹æœ€ä½³æ°´å¹³**ï¼Œå¹¶åœ¨ [Object HalBench](https://arxiv.org/abs/2312.00849) ä¸­**ä¼˜äºGPT-4V**ã€‚

- ğŸ•¹ **å®æ—¶å¤šæ¨¡æ€äº¤äº’ã€‚**

  æˆ‘ä»¬å°è¯•ç»“åˆOmniLMM-12Bå’ŒGPT-3.5 (çº¯æ–‡æœ¬æ¨¡å‹) ï¼Œå®ç°**å®æ—¶å¤šæ¨¡æ€äº¤äº’åŠ©æ‰‹**ã€‚è¯¥æ¨¡å‹æ¥å—æ¥è‡ªæ‘„åƒå¤´çš„è§†é¢‘æµï¼Œå¹¶å€ŸåŠ©å·¥å…·å¤„ç†è¯­éŸ³è¾“å…¥è¾“å‡ºã€‚è™½ç„¶è¿˜å¾ˆåˆæ­¥ï¼Œæˆ‘ä»¬å‘ç°è¯¥æ¨¡å‹æ— éœ€è§†é¢‘ç¼–è¾‘å¯ä»¥**å¤ç°Geminiæ¼”ç¤ºè§†é¢‘ä¸­çš„ä¸€äº›æœ‰è¶£ä¾‹å­**ã€‚

### è¯„æµ‹ç»“æœ <!-- omit in toc -->

<div align="center">
    <img src=assets/radar_omnilmm12b.png width=66% />
</div>
<details>
<summary> MME, MMBench, MMMU, MMBench, MMHal-Bench, Object HalBench, SeedBench, LLaVA Bench W, MathVista ä¸Šçš„è¯¦ç»†è¯„æµ‹ç»“æœã€‚ </summary>

<table>
<thead>
  <tr>
    <th align="left">Model</th>
    <th>Size</th>
    <th>MME</th>
    <th nowrap="nowrap">MMB dev (en)</th>
    <th nowrap="nowrap" >MMMU val</th>
    <th nowrap="nowrap" >MMHal-Bench</th>
    <th nowrap="nowrap" >Object HalBench</th>
    <th nowrap="nowrap" >SeedBench-I</th>
    <th>MathVista</th>
    <th nowrap="nowrap" >LLaVA Bench</th>
  </tr>
</thead>
<tbody align="center">
  <tr>
    <td align="left">GPT-4Vâ€ </td>
    <td>-</td>
    <td>1771.5</td>
    <td>75.1 </td>
    <td>56.8</td>
    <td>3.53 / 70.8</td>
    <td>86.4 / 92.7</td>
    <td>71.6 </td>
    <td>47.8 </td>
    <td>93.1 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left">Qwen-VL-Plusâ€ </td>
    <td>-</td>
    <td>2183.4</td>
    <td>66.2 </td>
    <td>45.2</td>
    <td>- </td>
    <td>- </td>
    <td>65.7 </td>
    <td>36.0 </td>
    <td>73.7 </td>
  </tr>
  <tr>
    <td align="left">Yi-VL 6B</td>
    <td align="right">6.7B </td>
    <td>1915.1 </td>
    <td>68.6 </td>
    <td>40.3 </td>
    <td>- </td>
    <td>- </td>
    <td>67.5 </td>
    <td>28.8 </td>
    <td>51.9 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" >Qwen-VL-Chat</td>
    <td align="right">9.6B</td>
    <td>1860.0</td>
    <td>60.6 </td>
    <td>35.9</td>
    <td>2.93 / 59.4</td>
    <td>56.2 / 80.0</td>
    <td>64.8 </td>
    <td>33.8 </td>
    <td>67.7 </td>
  </tr>
  <tr>
    <td align="left" >CogVLM-Chat</td>
    <td align="right">17.4B</td>
    <td>1736.6</td>
    <td>63.7 </td>
    <td>32.1 </td>
    <td>2.68 / 52.1 </td>
    <td>73.6 / 87.4 </td>
    <td>68.8 </td>
    <td>34.7 </td>
    <td>73.9 </td>
  </tr>
  <tr>
    <td align="left" >LLaVA 1.5</td>
    <td align="right">13.6B </td>
    <td>1808.4 </td>
    <td>68.2 </td>
    <td>36.4 </td>
    <td>2.71 / 51.0 </td>
    <td>53.7 / 77.4 </td>
    <td>68.1 </td>
    <td>26.4 </td>
    <td>64.6 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" ><b>OmniLMM-12B</b></td>
    <td align="right">11.6B </td>
    <td>1935.8 </td>
    <td>71.6 </td>
    <td>40.7 </td>
    <td>3.45 / 68.8 </td>
    <td>90.3 / 95.5 </td>
    <td>71.1 </td>
    <td>34.9 </td>
    <td>72.0 </td>
  </tr>
</tbody>
</table>
<small>â€ : é—­æºæ¨¡å‹</small>
<br>
</details>

### å…¸å‹ç¤ºä¾‹ <!-- omit in toc -->

<table align="center" >
  <p align="center" > 
    <img src="assets/omnilmm-12b-examples_2.png" />
  </p>
</table>


æˆ‘ä»¬ç»“åˆ OmniLMM-12B å’Œ ChatGPT-3.5 (çº¯æ–‡æœ¬æ¨¡å‹) å°è¯•æ„å»º **å®æ—¶å¤šæ¨¡æ€äº¤äº’åŠ©æ‰‹**. OmniLMM-12B å°†è§†é¢‘å¸§è½¬ä¸ºå¯¹åº”çš„å›¾åƒæè¿°å¹¶è¾“å…¥ç»™ChatGPT-3.5æ¥ç”Ÿæˆå¯¹ç”¨æˆ·æŒ‡ä»¤çš„å“åº”ã€‚æ¼”ç¤ºè§†é¢‘æœªç»ç¼–è¾‘ã€‚

<div align="center" >
  <video controls src="https://github.com/OpenBMB/OmniLMM/assets/157115220/8fec13bf-bb47-4bf8-8f8c-d0b716a964ec" type="video/mp4" width=80%/>
</div>

## Online Demo

æ¬¢è¿é€šè¿‡ä»¥ä¸‹é“¾æ¥ä½¿ç”¨æˆ‘ä»¬çš„ç½‘é¡µç«¯æ¨ç†æœåŠ¡ï¼š [OmniLMM-12B](http://120.92.209.146:8081) ï½œ [MiniCPM-V 2.0](http://120.92.209.146:80).

## å®‰è£…

1. å…‹éš†æˆ‘ä»¬çš„ä»“åº“å¹¶è·³è½¬åˆ°ç›¸åº”ç›®å½•

```bash
git clone https://github.com/OpenBMB/MiniCPM-V.git
cd MiniCPM-V
```

1. åˆ›å»º conda ç¯å¢ƒ

```Shell
conda create -n MiniCPMV python=3.10 -y
conda activate MiniCPMV
```

3. å®‰è£…ä¾èµ–

```shell
pip install -r requirements.txt
```

## æ¨ç†

### æ¨¡å‹åº“

| æ¨¡å‹                | ç®€ä»‹       | ä¸‹è½½é“¾æ¥ |
|:----------------------|:-------------------|:---------------:|
| MiniCPM-V 2.0  | æœ€æ–°ç‰ˆæœ¬ï¼Œæä¾›é«˜æ•ˆè€Œé¢†å…ˆçš„ç«¯ä¾§åŒè¯­å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚   |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-V-2) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-V-2/files) |
| MiniCPM-V  | ç¬¬ä¸€ç‰ˆ MiniCPM-V    |   [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-V) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-V/files) |
| OmniLMM-12B | æ€§èƒ½æœ€å¼ºçš„ç‰ˆæœ¬                   |  [ğŸ¤—](https://huggingface.co/openbmb/OmniLMM-12B) &nbsp;&nbsp;  [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/OmniLMM-12B/files) |


### å¤šè½®å¯¹è¯

è¯·å‚è€ƒä»¥ä¸‹ä»£ç ä½¿ç”¨ `MiniCPM-V` å’Œ `OmniLMM` è¿›è¡Œæ¨ç†ã€‚

<div align="center">
<img src="assets/hk_OCR.jpg" width="500px">
</div>


```python
from chat import OmniLMMChat, img2base64

chat_model = OmniLMMChat('openbmb/MiniCPM-V-2') # or 'openbmb/OmniLMM-12B'

im_64 = img2base64('./assets/hk_OCR.jpg')

# First round chat 
msgs = [{"role": "user", "content": "Where should I go to buy a camera?"}]

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.chat(inputs)
print(answer)

# Second round chat 
# pass history context of multi-turn conversation
msgs.append({"role": "assistant", "content": answer})
msgs.append({"role": "user", "content": "Where is this store in the image?"})

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.chat(inputs)
print(answer)
```

å¯ä»¥å¾—åˆ°ä»¥ä¸‹è¾“å‡º:

```
"You should go to the Canon store for a camera."

"The Canon store is located on the right side of the image."
```



### Mac æ¨ç†
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ MiniCPM-V 2.0 åŸºäºMac MPSè¿è¡Œ (Apple silicon or AMD GPUs)çš„ç¤ºä¾‹ã€‚ </summary>

```python
# test.py
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True, torch_dtype=torch.bfloat16)
model = model.to(device='mps', dtype=torch.float16)

tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True)
model.eval()

image = Image.open('./assets/hk_OCR.jpg').convert('RGB')
question = 'Where is this photo taken?'
msgs = [{'role': 'user', 'content': question}]

answer, context, _ = model.chat(
    image=image,
    msgs=msgs,
    context=None,
    tokenizer=tokenizer,
    sampling=True
)
print(answer)
```
è¿è¡Œ:
```shell
PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py
```
</details>


### æ‰‹æœºç«¯éƒ¨ç½²
MiniCPM-V 2.0 ç›®å‰å¯ä»¥éƒ¨ç½²åœ¨Androidå’ŒHarmonyæ“ä½œç³»ç»Ÿçš„æ‰‹æœºä¸Šã€‚ ğŸš€ ç‚¹å‡»[è¿™é‡Œ](https://github.com/OpenBMB/mlc-MiniCPM)å¼€å§‹æ‰‹æœºç«¯éƒ¨ç½²ã€‚

### æœ¬åœ°WebUI Demoéƒ¨ç½²
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹æœ¬åœ°WebUI demoåœ¨Nvidia GPU, Macç­‰ä¸åŒè®¾å¤‡éƒ¨ç½²æ–¹æ³• </summary>
  
```shell
pip install -r requirements.txt
```
  
```shell
# For Nvidia GPUs support BF16 (like A100, H100, RTX3090), run:
python web_demo.py --device cuda --dtype bf16

# For Nvidia GPUs do NOT support BF16 (like V100, T4, RTX2080), run:
python web_demo.py --device cuda --dtype fp16

# For Mac with MPS (Apple silicon or AMD GPUs), run:
PYTORCH_ENABLE_MPS_FALLBACK=1 python web_demo.py --device mps --dtype fp16
```
</details>

## å¾®è°ƒ

### MiniCPM-V <!-- omit in toc -->

æˆ‘ä»¬æ”¯æŒä½¿ç”¨ SWIFT æ¡†æ¶å¾®è°ƒ MiniCPM-V ç³»åˆ—æ¨¡å‹ã€‚SWIFT æ”¯æŒè¿‘ 200 ç§ LLM å’Œ MLLMï¼ˆå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼‰çš„è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹å’Œéƒ¨ç½²ã€‚æ”¯æŒ PEFT æä¾›çš„è½»é‡è®­ç»ƒæ–¹æ¡ˆå’Œå®Œæ•´çš„ Adapters åº“æ”¯æŒçš„æœ€æ–°è®­ç»ƒæŠ€æœ¯å¦‚ NEFTuneã€LoRA+ã€LLaMA-PRO ç­‰ã€‚ 

å‚è€ƒæ–‡æ¡£ï¼š[MiniCPM-V](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-væœ€ä½³å®è·µ.md), [MiniCPM-V-2](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-v-2æœ€ä½³å®è·µ.md)

## æœªæ¥è®¡åˆ’

- [x] æ”¯æŒ MiniCPM-V ç³»åˆ—æ¨¡å‹å¾®è°ƒ
- [ ] æ”¯æŒ OmniLMM ç³»åˆ—æ¨¡å‹å¾®è°ƒ
- [ ] å®æ—¶å¤šæ¨¡æ€äº¤äº’ä»£ç å¼€æº



## æ¨¡å‹åè®® <!-- omit in toc -->

æœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æº

OmniLMM æ¨¡å‹æƒé‡çš„ä½¿ç”¨éµå¾ª â€œ[é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ](https://github.com/OpenBMB/General-Model-License/blob/main/é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ.md)â€ã€‚

OmniLMM æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚

å¦‚éœ€å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·è”ç³» cpm@modelbest.cn æ¥è·å–ä¹¦é¢æˆæƒï¼Œç™»è®°åå¯ä»¥å…è´¹å•†ä¸šä½¿ç”¨ã€‚


## å£°æ˜ <!-- omit in toc -->

ä½œä¸ºå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ŒMiniCPM-V å’Œ OmniLMM é€šè¿‡å­¦ä¹ å¤§é‡çš„å¤šæ¨¡æ€æ•°æ®æ¥ç”Ÿæˆå†…å®¹ï¼Œä½†å®ƒæ— æ³•ç†è§£ã€è¡¨è¾¾ä¸ªäººè§‚ç‚¹æˆ–ä»·å€¼åˆ¤æ–­ï¼Œå®ƒæ‰€è¾“å‡ºçš„ä»»ä½•å†…å®¹éƒ½ä¸ä»£è¡¨æ¨¡å‹å¼€å‘è€…çš„è§‚ç‚¹å’Œç«‹åœºã€‚

å› æ­¤ç”¨æˆ·åœ¨ä½¿ç”¨ MiniCPM-V å’Œ OmniLMM ç”Ÿæˆçš„å†…å®¹æ—¶ï¼Œåº”è‡ªè¡Œè´Ÿè´£å¯¹å…¶è¿›è¡Œè¯„ä¼°å’ŒéªŒè¯ã€‚å¦‚æœç”±äºä½¿ç”¨ OmniLMM å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚


## æœºæ„ <!-- omit in toc -->

æœ¬é¡¹ç›®ç”±ä»¥ä¸‹æœºæ„å…±åŒå¼€å‘ï¼š

- <img src="assets/thunlp.png" width="28px"> [æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤](https://nlp.csai.tsinghua.edu.cn/)
- <img src="assets/modelbest.png" width="28px"> [é¢å£æ™ºèƒ½](https://modelbest.cn/)
- <img src="assets/zhihu.webp" width="28px"> [çŸ¥ä¹](https://www.zhihu.com/ )

## å…¶ä»–å¤šæ¨¡æ€é¡¹ç›® <!-- omit in toc -->

ğŸ‘ æ¬¢è¿äº†è§£æˆ‘ä»¬æ›´å¤šçš„å¤šæ¨¡æ€é¡¹ç›®ï¼š

[VisCPM](https://github.com/OpenBMB/VisCPM/tree/main) | [RLHF-V](https://github.com/RLHF-V/RLHF-V) | [LLaVA-UHD](https://github.com/thunlp/LLaVA-UHD)

## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬æ¨¡å‹/ä»£ç /è®ºæ–‡æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ â­ å’Œ å¼•ç”¨ ğŸ“ï¼Œæ„Ÿè°¢ï¼

```bib
@article{yu2023rlhf,
  title={Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback},
  author={Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others},
  journal={arXiv preprint arXiv:2312.00849},
  year={2023}
}
@article{viscpm,
    title={Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages}, 
    author={Jinyi Hu and Yuan Yao and Chongyi Wang and Shan Wang and Yinxu Pan and Qianyu Chen and Tianyu Yu and Hanghao Wu and Yue Zhao and Haoye Zhang and Xu Han and Yankai Lin and Jiao Xue and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal={arXiv preprint arXiv:2308.12038},
    year={2023}
}
@article{xu2024llava-uhd,
  title={{LLaVA-UHD}: an LMM Perceiving Any Aspect Ratio and High-Resolution Images},
  author={Xu, Ruyi and Yao, Yuan and Guo, Zonghao and Cui, Junbo and Ni, Zanlin and Ge, Chunjiang and Chua, Tat-Seng and Liu, Zhiyuan and Huang, Gao},
  journal={arXiv preprint arXiv:2403.11703},
  year={2024}
}
```
