<div align="center">

<!-- <!-- <h1 style="color: #33A6B8; font-family: Helvetica"> OmniLMM </h1> -->

<img src="./assets/title-2.png" width="200em" ></img> 

**æ€§èƒ½é¢†å…ˆä¸”éƒ¨ç½²é«˜æ•ˆçš„å¤šæ¨¡æ€å¤§æ¨¡å‹**
<p align="center">
  OmniLMM-3B  <a href="https://huggingface.co/openbmb/MiniCPM-V/">ğŸ¤—</a> <a href="http://120.92.209.146:80/">ğŸ¤–</a> |
  OmniLMM-12B <a href="https://huggingface.co/openbmb/OmniLMM-12B/">ğŸ¤—</a> <a href="http://120.92.209.146:8081">ğŸ¤–</a>
</p>

</div>


**OmniLMM** æ˜¯é¢å‘å›¾æ–‡ç†è§£çš„å¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ã€‚è¯¥ç³»åˆ—æ¨¡å‹æ¥å—å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œå¹¶æä¾›é«˜è´¨é‡çš„æ–‡æœ¬è¾“å‡ºã€‚æˆ‘ä»¬å‘å¸ƒäº†ä¸¤ä¸ªç‰ˆæœ¬çš„ OmniLMMï¼Œæ—¨åœ¨å®ç°**é¢†å…ˆçš„æ€§èƒ½å’Œé«˜æ•ˆçš„éƒ¨ç½²**ï¼š

- **OmniLMM-12B**ï¼šç›¸æ¯”åŒè§„æ¨¡å…¶ä»–æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å…·æœ‰é¢†å…ˆæ€§èƒ½ã€‚

- **OmniLMM-3B**ï¼šå¯åœ¨ç»ˆç«¯è®¾å¤‡ä¸Šéƒ¨ç½²å¹¶å…·å¤‡å…ˆè¿›çš„å¤šæ¨¡æ€å¯¹è¯èƒ½åŠ›ã€‚

[English Document](./README.md)

## ç›®å½•
<!-- TOC -->

- [ç›®å½•](#ç›®å½•)
- [OmniLMM-12B](#omnilmm-12b)
  - [è¯„æµ‹ç»“æœ](#è¯„æµ‹ç»“æœ)
  - [å…¸å‹ç¤ºä¾‹](#å…¸å‹ç¤ºä¾‹)
- [OmniLMM-3B](#omnilmm-3b)
  - [æ€§èƒ½è¯„ä¼°](#æ€§èƒ½è¯„ä¼°)
  - [éƒ¨ç½²ç¤ºä¾‹](#éƒ¨ç½²ç¤ºä¾‹)
- [Demo](#demo)
- [å®‰è£…](#å®‰è£…)
- [æ¨ç†](#æ¨ç†)
  - [æ¨¡å‹åº“](#æ¨¡å‹åº“)
  - [å¤šè½®å¯¹è¯](#å¤šè½®å¯¹è¯)
  - [æ‰‹æœºç«¯éƒ¨ç½²](#æ‰‹æœºç«¯éƒ¨ç½²)
- [æœªæ¥è®¡åˆ’](#æœªæ¥è®¡åˆ’)
- [æ¨¡å‹åè®®](#æ¨¡å‹åè®®)
- [å£°æ˜](#å£°æ˜)
- [æœºæ„](#æœºæ„)

<!-- /TOC -->
<!-- /TOC -->
## OmniLMM-12B
**OmniLMM-12B** æ˜¯å½“å‰ç³»åˆ—ä¸­æ€§èƒ½æœ€ä½³çš„ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹åŸºäºEVA02-5Bå’ŒZephyr-7B-Î²åˆå§‹åŒ–æ„å»ºï¼Œå¹¶ä½¿ç”¨perceiver resamplerè¿æ¥ï¼Œé‡‡ç”¨äº†è¯¾ç¨‹å­¦ä¹ çš„æ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹å…·æœ‰ä¸‰ä¸ªç‰¹ç‚¹ï¼š

- ğŸ”¥ **æ€§èƒ½é¢†å…ˆã€‚**

  OmniLMM-12B ç›¸æ¯”å…¶ä»–åŒè§„æ¨¡æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—**é¢†å…ˆçš„æ€§èƒ½**ï¼ˆåŒ…æ‹¬ MMEã€MMBenchã€SEED-Bench ç­‰ï¼‰ï¼Œæ¨¡å‹æŒæ¡äº†è¾ƒä¸ºä¸°å¯Œçš„å¤šæ¨¡æ€ä¸–ç•ŒçŸ¥è¯†ã€‚

- ğŸ† **è¡Œä¸ºå¯ä¿¡ã€‚**

  å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜å¤‡å—å…³æ³¨ï¼Œæ¨¡å‹ç»å¸¸ç”Ÿæˆå’Œå›¾åƒä¸­çš„äº‹å®ä¸ç¬¦çš„æ–‡æœ¬ï¼ˆä¾‹å¦‚ï¼Œç¡®ä¿¡åœ°æè¿°å›¾ç‰‡ä¸­å¹¶ä¸å­˜åœ¨çš„ç‰©ä½“ï¼‰ã€‚OmniLMM-12Bæ˜¯ **ç¬¬ä¸€ä¸ªé€šè¿‡å¤šæ¨¡æ€ RLHF å¯¹é½çš„ç»¼åˆèƒ½åŠ›ä¼˜ç§€çš„å¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ˆå€ŸåŠ©æœ€æ–°çš„ [RLHF-V](https://rlhf-v.github.io/) æŠ€æœ¯ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ [MMHal-Bench](https://huggingface.co/datasets/Shengcao1006/MMHal-Bench) å¹»è§‰è¯„æµ‹åŸºå‡†ä¸Šè¾¾åˆ°**å¼€æºæ¨¡å‹æœ€ä½³æ°´å¹³**ï¼Œå¹¶åœ¨ [Object HalBench](https://arxiv.org/abs/2312.00849) ä¸­**ä¼˜äºGPT-4V**ã€‚

- ğŸ•¹ **å®æ—¶å¤šæ¨¡æ€äº¤äº’ã€‚**

  æˆ‘ä»¬å°è¯•ç»“åˆOmniLMM-12Bå’ŒGPT-3.5 (çº¯æ–‡æœ¬æ¨¡å‹) ï¼Œå®ç°**å®æ—¶å¤šæ¨¡æ€äº¤äº’åŠ©æ‰‹**ã€‚è¯¥æ¨¡å‹æ¥å—æ¥è‡ªæ‘„åƒå¤´çš„è§†é¢‘æµï¼Œå¹¶å€ŸåŠ©å·¥å…·å¤„ç†è¯­éŸ³è¾“å…¥è¾“å‡ºã€‚è™½ç„¶è¿˜å¾ˆåˆæ­¥ï¼Œæˆ‘ä»¬å‘ç°è¯¥æ¨¡å‹æ— éœ€è§†é¢‘ç¼–è¾‘å¯ä»¥**å¤ç°Geminiæ¼”ç¤ºè§†é¢‘ä¸­çš„ä¸€äº›æœ‰è¶£ä¾‹å­**ã€‚

### è¯„æµ‹ç»“æœ

<div align="center">
    <img src=assets/eval_radar.png width=66% />
</div>
<details>
<summary> MME, MMBench, MMMU, MMBench, MMHal-Bench, Object HalBench, SeedBench, LLaVA Bench W, MathVista ä¸Šçš„è¯¦ç»†è¯„æµ‹ç»“æœ. </summary>

<table>
<thead>
  <tr>
    <th align="left">Model</th>
    <th>Size</th>
    <th>MME</th>
    <th nowrap="nowrap">MMB dev (en)</th>
    <th nowrap="nowrap" >MMMU val</th>
    <th nowrap="nowrap" >MMHal-Bench</th>
    <th nowrap="nowrap" >Object HalBench</th>
    <th nowrap="nowrap" >SeedBench-I</th>
    <th>MathVista</th>
    <th nowrap="nowrap" >LLaVA Bench W</th>
  </tr>
</thead>
<tbody align="center">
  <tr>
    <td align="left">GPT-4Vâ€ </td>
    <td>-</td>
    <td>1409</td>
    <td>75.1 </td>
    <td>56.8</td>
    <td>3.53 / 70.8</td>
    <td>86.4 / 92.7</td>
    <td>71.6 </td>
    <td>47.8 </td>
    <td>93.1 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left">Qwen-VL-Plusâ€ </td>
    <td>-</td>
    <td>1681</td>
    <td>66.2 </td>
    <td>45.2</td>
    <td>- </td>
    <td>- </td>
    <td>65.7 </td>
    <td>36.0 </td>
    <td>73.7 </td>
  </tr>
  <tr>
    <td align="left">Yi-VL 6B</td>
    <td align="right">6.7B </td>
    <td>- </td>
    <td>68.2 </td>
    <td>39.1 </td>
    <td>- </td>
    <td>- </td>
    <td>66.1 </td>
    <td>28.0 </td>
    <td>39.9 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" >Qwen-VL-Chat</td>
    <td align="right">9.6B</td>
    <td>1488</td>
    <td>60.6 </td>
    <td>35.9</td>
    <td>2.93 / 59.4</td>
    <td>56.2 / 80.0</td>
    <td>64.8 </td>
    <td>33.8 </td>
    <td>67.7 </td>
  </tr>
  <tr>
    <td align="left" >CogVLM</td>
    <td align="right">17.4B</td>
    <td>1438</td>
    <td>63.7 </td>
    <td>32.1 </td>
    <td>2.68 / 52.1 </td>
    <td>73.6 / 87.4 </td>
    <td>68.8 </td>
    <td>34.7 </td>
    <td>73.9 </td>
  </tr>
  <tr>
    <td align="left" >LLaVA 1.5</td>
    <td align="right">13.6B </td>
    <td>1531 </td>
    <td>68.2 </td>
    <td>36.4 </td>
    <td>2.71 / 51.0 </td>
    <td>53.7 / 77.4 </td>
    <td>68.1 </td>
    <td>26.4 </td>
    <td>64.6 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" ><b>OmniLMM-12B</b></td>
    <td align="right">11.6B </td>
    <td>1637 </td>
    <td>71.6 </td>
    <td>40.7 </td>
    <td>3.45 / 68.8 </td>
    <td>90.3 / 95.5 </td>
    <td>71.1 </td>
    <td>34.9 </td>
    <td>72.0 </td>
  </tr>
</tbody>
</table>
<small>â€ : é—­æºæ¨¡å‹</small>
</br>
</details>

### å…¸å‹ç¤ºä¾‹

<table align="center" >
  <p align="center" > 
    <img src="assets/omnilmm-12b-examples_2.png" />
  </p>
</table>


æˆ‘ä»¬ç»“åˆ OmniLMM-12B å’Œ ChatGPT-3.5 (çº¯æ–‡æœ¬æ¨¡å‹) å°è¯•æ„å»º **å®æ—¶å¤šæ¨¡æ€äº¤äº’åŠ©æ‰‹**. OmniLMM-12B å°†è§†é¢‘å¸§è½¬ä¸ºå¯¹åº”çš„å›¾åƒæè¿°å¹¶è¾“å…¥ç»™ChatGPT-3.5æ¥ç”Ÿæˆå¯¹ç”¨æˆ·æŒ‡ä»¤çš„å“åº”ã€‚æ¼”ç¤ºè§†é¢‘æœªç»ç¼–è¾‘ã€‚

<div align="center" >
  <video controls src="https://github.com/OpenBMB/OmniLMM/assets/157115220/c1fd3562-1ab1-4534-8139-79e9137b5398" type="video/mp4" width=80%/>
</div>

## OmniLMM-3B

**OmniLMM-3B**ï¼ˆå³ MiniCPM-Vï¼‰å¯ä»¥é«˜æ•ˆéƒ¨ç½²åˆ°ç»ˆç«¯è®¾å¤‡ã€‚è¯¥æ¨¡å‹åŸºäº SigLip-400M å’Œ [MiniCPM-2.4B](https://github.com/OpenBMB/MiniCPM/)æ„å»ºï¼Œé€šè¿‡perceiver resamplerè¿æ¥ã€‚OmniLMM-3Bçš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- âš¡ï¸ **é«˜æ•ˆéƒ¨ç½²ã€‚**

  OmniLMM-3B å¯ä»¥**é«˜æ•ˆéƒ¨ç½²åœ¨å¤§å¤šæ•° GPU å’Œä¸ªäººç”µè„‘ä¸Š**ï¼ŒåŒ…æ‹¬**ç§»åŠ¨æ‰‹æœºç­‰ç»ˆç«¯è®¾å¤‡**ã€‚åœ¨è§†è§‰ç¼–ç æ–¹é¢ï¼Œæˆ‘ä»¬é€šè¿‡perceiver resamplerå°†å›¾åƒè¡¨ç¤ºå‹ç¼©ä¸º64ä¸ªtokenï¼Œè¿œè¿œå°‘äºåŸºäºMLPæ¶æ„çš„å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆé€šå¸¸å¤§äº512ä¸ªtokenï¼‰ã€‚è¿™ä½¿å¾— OmniLMM-3B åœ¨æ¨ç†æœŸé—´**å­˜å‚¨å ç”¨æ›´ä½å¹¶ä¸”é€Ÿåº¦æ›´å¿«**ã€‚

- ğŸ”¥ **ä¼˜ç§€çš„æ€§èƒ½ã€‚**

  OmniLMM-3B åœ¨å¤šä¸ªæµ‹è¯•åŸºå‡†ä¸­å®ç°äº†åŒè§„æ¨¡**æœ€ä½³æ€§èƒ½**ï¼Œè¶…è¿‡äº†åŸºäºPhi-2æ„å»ºçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç”šè‡³åœ¨éƒ¨åˆ†åŸºå‡†ä¸­å®ç°äº†**ä¸9.6B Qwen-VL-ChatåŒ¹é…æˆ–æ›´å¥½çš„æ€§èƒ½**ã€‚

- ğŸ™Œ **åŒè¯­æ”¯æŒã€‚**

  OmniLMM-3B æ˜¯**ç¬¬ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­çš„ç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹**ã€‚
  è¯¥èƒ½åŠ›é€šè¿‡ICLR 2024 spotlight [è®ºæ–‡](https://arxiv.org/abs/2308.12038)ä¸­æå‡ºçš„å¤šæ¨¡æ€èƒ½åŠ›çš„è·¨è¯­è¨€æ³›åŒ–æŠ€æœ¯å®ç°ã€‚

### æ€§èƒ½è¯„ä¼°

<div align="center">

<table style="margin: 0px auto;">
<thead>
  <tr>
    <th align="left">Model</th>
    <th>Size</th>
    <th>MME</th>
    <th nowrap="nowrap" >MMB dev (en)</th>
    <th nowrap="nowrap" >MMB dev (zh)</th>
    <th nowrap="nowrap" >MMMU val</th>
    <th nowrap="nowrap" >CMMMU val</th>
  </tr>
</thead>
<tbody align="center">
  <tr>
    <td align="left">LLaVA-Phi</td>
    <td align="right">3B</td>
    <td>1335</td>
    <td>59.8</td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left">MobileVLM</td>
    <td align="right">3B</td>
    <td>1289</td>
    <td>59.6</td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" >Imp-v1</td>
    <td align="right">3B</td>
    <td>1434</td>
    <td>66.5</td>
    <td>- </td>
    <td>- </td>
    <td>- </td>
  </tr>
  <tr>
    <td align="left" >Qwen-VL-Chat</td>
    <td align="right" >9.6B</td>
    <td>1487</td>
    <td>60.6 </td>
    <td>56.7 </td>
    <td>35.9 </td>
    <td>30.7 </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" >CogVLM</td>
    <td align="right">17.4B </td>
    <td>1438 </td>
    <td>63.7 </td>
    <td>53.8 </td>
    <td>32.1 </td>
    <td>- </td>
  </tr>
  <tr>
    <td nowrap="nowrap" align="left" ><b>OmniLMM-3B</b></td>
    <td align="right">3B </td>
    <td>1452 </td>
    <td>67.3 </td>
    <td>61.9 </td>
    <td>34.7 </td>
    <td>32.1 </td>
  </tr>
</tbody>
</table>

</div>

### éƒ¨ç½²ç¤ºä¾‹

æˆ‘ä»¬åœ¨æ‰‹æœºä¸Šéƒ¨ç½²äº†OmniLMM-3Bã€‚æ¼”ç¤ºè§†é¢‘æ˜¯OnePlus 9Rä¸Šçš„åŸå§‹å½•å±ç»“æœã€‚

<table align="center" >
  <p align="center" > 
    <img src="assets/Snake_cn_Mushroom_en.gif" width=48%/>
  </p>
</table>

## Demo

æ¬¢è¿é€šè¿‡ä»¥ä¸‹é“¾æ¥ä½¿ç”¨æˆ‘ä»¬çš„ç½‘é¡µç«¯æ¨ç†æœåŠ¡ï¼š [OmniLMM-12B](http://120.92.209.146:8081) ï½œ [OmniLMM-3B](http://120.92.209.146:80).

## å®‰è£…

1. å…‹éš†æˆ‘ä»¬çš„ä»“åº“å¹¶è·³è½¬åˆ°ç›¸åº”ç›®å½•

```bash
git clone https://github.com/OpenBMB/OmniLMM.git
cd OmniLMM
```

1. åˆ›å»º conda ç¯å¢ƒ

```Shell
conda create -n OmniLMM python=3.10 -y
conda activate OmniLMM
```

3. å®‰è£…ä¾èµ–

```shell
pip install -r requirements.txt
```

## æ¨ç†

### æ¨¡å‹åº“

| æ¨¡å‹                | ç®€ä»‹       | ä¸‹è½½é“¾æ¥ |
|:----------------------|:-------------------|:---------------:|
| OmniLMM-12B | æ€§èƒ½æœ€å¼ºçš„ç‰ˆæœ¬                   |  [ğŸ¤—](https://huggingface.co/openbmb/OmniLMM-12B) &nbsp;&nbsp;  [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/OmniLMM-12B/files) |
| OmniLMM-3B  | æ”¯æŒç«¯ä¾§é«˜æ•ˆéƒ¨ç½²ï¼Œæ€§èƒ½ä¼˜ç§€          |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-V) &nbsp;&nbsp;  [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-V/files) |


### å¤šè½®å¯¹è¯

è¯·å‚è€ƒä»¥ä¸‹ä»£ç ä½¿ç”¨ `OmniLMM` è¿›è¡Œæ¨ç†ã€‚

<div align="center">
<img src="assets/worldmap_ck.jpg" width="500px">
</div>


```python
from chat import OmniLMMChat, img2base64

chat_model = OmniLMMChat('openbmb/OmniLMM-12B') # or 'openbmb/MiniCPM-V'

im_64 = img2base64('./assets/worldmap_ck.jpg')

# First round chat 
msgs = [{"role": "user", "content": "What is interesting about this image?"}]

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.process(inputs)
print(answer)

# Second round chat 
# pass history context of multi-turn conversation
msgs.append({"role": "assistant", "content": answer})
msgs.append({"role": "user", "content": "Where is China in the image"})

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.process(inputs)
print(answer)
```

å¯ä»¥å¾—åˆ°ä»¥ä¸‹è¾“å‡º:
```
"The interesting aspect of this image is the shape of the chicken nuggets on the pan. The nuggets are shaped like the continents of the world, which is an unusual and creative way to present the food. It adds a fun and playful element to the meal, making it more visually appealing and engaging."

"In the image, China is located on the right side of the pan. It is one of the nuggets shaped like the continents of the world, and its placement on the right side of the pan is consistent with its geographical location in the real world"
```
### æ‰‹æœºç«¯éƒ¨ç½²
OmniLMM-3B (å³MiniCPM-V) ç›®å‰å¯ä»¥éƒ¨ç½²åœ¨Androidå’ŒHarmonyæ“ä½œç³»ç»Ÿçš„æ‰‹æœºä¸Šã€‚ ğŸš€ ç‚¹å‡»[è¿™é‡Œ](https://github.com/OpenBMB/mlc-MiniCPM)å¼€å§‹æ‰‹æœºç«¯éƒ¨ç½²ã€‚


## æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒæ¨¡å‹å¾®è°ƒ
- [ ] æœ¬åœ°ç”¨æˆ·å›¾å½¢ç•Œé¢éƒ¨ç½²
- [ ] å®æ—¶å¤šæ¨¡æ€äº¤äº’ä»£ç å¼€æº



## æ¨¡å‹åè®®

æœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æº

OmniLMM æ¨¡å‹æƒé‡çš„ä½¿ç”¨éµå¾ª â€œ[é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ](https://github.com/OpenBMB/General-Model-License/blob/main/é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ.md)â€ã€‚

OmniLMM æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚

å¦‚éœ€å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·è”ç³» cpm@modelbest.cn æ¥è·å–ä¹¦é¢æˆæƒï¼Œç™»è®°åå¯ä»¥å…è´¹å•†ä¸šä½¿ç”¨ã€‚


## å£°æ˜

ä½œä¸ºå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ŒOmniLMM é€šè¿‡å­¦ä¹ å¤§é‡çš„å¤šæ¨¡æ€æ•°æ®æ¥ç”Ÿæˆå†…å®¹ï¼Œä½†å®ƒæ— æ³•ç†è§£ã€è¡¨è¾¾ä¸ªäººè§‚ç‚¹æˆ–ä»·å€¼åˆ¤æ–­ï¼Œå®ƒæ‰€è¾“å‡ºçš„ä»»ä½•å†…å®¹éƒ½ä¸ä»£è¡¨æ¨¡å‹å¼€å‘è€…çš„è§‚ç‚¹å’Œç«‹åœºã€‚

å› æ­¤ç”¨æˆ·åœ¨ä½¿ç”¨ OmniLMM ç”Ÿæˆçš„å†…å®¹æ—¶ï¼Œåº”è‡ªè¡Œè´Ÿè´£å¯¹å…¶è¿›è¡Œè¯„ä¼°å’ŒéªŒè¯ã€‚å¦‚æœç”±äºä½¿ç”¨ OmniLMM å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚


## æœºæ„

æœ¬é¡¹ç›®ç”±ä»¥ä¸‹æœºæ„å…±åŒå¼€å‘ï¼š

- <img src="assets/thunlp.png" width="28px"> [æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤](https://nlp.csai.tsinghua.edu.cn/)
- <img src="assets/modelbest.png" width="28px"> [é¢å£æ™ºèƒ½](https://modelbest.cn/)
- <img src="assets/zhihu.webp" width="28px"> [çŸ¥ä¹](https://www.zhihu.com/ )

