<div align="center">

<!-- <!-- <h1 style="color: #33A6B8; font-family: Helvetica"> OmniLMM </h1> -->

<img src="./assets/minicpmv.png" width="300em" ></img> 

**ç«¯ä¾§å¯ç”¨çš„ GPT-4V çº§å¤šæ¨¡æ€å¤§æ¨¡å‹**

  <strong>ä¸­æ–‡ |
  [English](./README_en.md)</strong>

 åŠ å…¥æˆ‘ä»¬çš„ <a href="docs/wechat.md" target="_blank"> ğŸ’¬ å¾®ä¿¡ç¤¾åŒº</a> 

<p align="center">
  MiniCPM-Llama3-V  2.5  <a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5/">ğŸ¤—</a> <a href="https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5">ğŸ¤–</a> |
  MiniCPM-V 2.0  <a href="https://huggingface.co/openbmb/MiniCPM-V-2/">ğŸ¤—</a> <a href="https://huggingface.co/spaces/openbmb/MiniCPM-V-2">ğŸ¤–</a> |
  <a href="https://openbmb.vercel.app/minicpm-v-2">MiniCPM-V 2.0 æŠ€æœ¯åšå®¢</a>
</p>

</div>


**MiniCPM-V**æ˜¯é¢å‘å›¾æ–‡ç†è§£çš„ç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ã€‚è¯¥ç³»åˆ—æ¨¡å‹æ¥å—å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œå¹¶æä¾›é«˜è´¨é‡çš„æ–‡æœ¬è¾“å‡ºã€‚è‡ª2024å¹´2æœˆä»¥æ¥ï¼Œæˆ‘ä»¬å…±å‘å¸ƒäº†4ä¸ªç‰ˆæœ¬æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°**é¢†å…ˆçš„æ€§èƒ½å’Œé«˜æ•ˆçš„éƒ¨ç½²**ï¼Œç›®å‰è¯¥ç³»åˆ—æœ€å€¼å¾—å…³æ³¨çš„æ¨¡å‹åŒ…æ‹¬ï¼š

- **MiniCPM-Llama3-V 2.5**ï¼šğŸ”¥ğŸ”¥ğŸ”¥ MiniCPM-Vç³»åˆ—çš„æœ€æ–°ã€æ€§èƒ½æœ€ä½³æ¨¡å‹ã€‚æ€»å‚æ•°é‡8Bï¼Œå¤šæ¨¡æ€ç»¼åˆæ€§èƒ½**è¶…è¶Š GPT-4V-1106ã€Gemini Proã€Claude 3ã€Qwen-VL-Max ç­‰å•†ç”¨é—­æºæ¨¡å‹**ï¼ŒOCR èƒ½åŠ›åŠæŒ‡ä»¤è·Ÿéšèƒ½åŠ›è¿›ä¸€æ­¥æå‡ï¼Œå¹¶**æ”¯æŒè¶…è¿‡30ç§è¯­è¨€**çš„å¤šæ¨¡æ€äº¤äº’ã€‚é€šè¿‡ç³»ç»Ÿä½¿ç”¨æ¨¡å‹é‡åŒ–ã€CPUã€NPUã€ç¼–è¯‘ä¼˜åŒ–ç­‰é«˜æ•ˆæ¨ç†æŠ€æœ¯ï¼ŒMiniCPM-Llama3-V 2.5 å¯ä»¥å®ç°**é«˜æ•ˆçš„ç»ˆç«¯è®¾å¤‡éƒ¨ç½²**ã€‚

- **MiniCPM-V 2.0**ï¼šMiniCPM-Vç³»åˆ—çš„æœ€è½»é‡çº§æ¨¡å‹ã€‚æ€»å‚æ•°é‡2Bï¼Œå¤šæ¨¡æ€ç»¼åˆæ€§èƒ½è¶…è¶Š Yi-VL 34Bã€CogVLM-Chat 17Bã€Qwen-VL-Chat 10B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼Œå¯æ¥å— 180 ä¸‡åƒç´ çš„ä»»æ„é•¿å®½æ¯”å›¾åƒè¾“å…¥ï¼Œå®ç°äº†å’Œ Gemini Pro ç›¸è¿‘çš„åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä»¥åŠå’Œ GPT-4V ç›¸åŒ¹çš„ä½å¹»è§‰ç‡ã€‚



## æ›´æ–°æ—¥å¿— <!-- omit in toc -->

#### ğŸ“Œ ç½®é¡¶

* [2024.05.28] ğŸ’¥ MiniCPM-Llama3-V 2.5 ç°åœ¨åœ¨ llama.cpp å’Œ ollama ä¸­å®Œå…¨æ”¯æŒå…¶åŠŸèƒ½ï¼**è¯·æ‹‰å–æˆ‘ä»¬æœ€æ–°çš„ fork æ¥ä½¿ç”¨**ï¼š[llama.cpp](https://github.com/OpenBMB/llama.cpp/blob/minicpm-v2.5/examples/minicpmv/README.md) & [ollama](https://github.com/OpenBMB/ollama/tree/minicpm-v2.5/examples/minicpm-v2.5)ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†å„ç§å¤§å°çš„ GGUF ç‰ˆæœ¬ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf/tree/main)æŸ¥çœ‹ã€‚è¯·æ³¨æ„ï¼Œ**ç›®å‰å®˜æ–¹ä»“åº“å°šæœªæ”¯æŒ MiniCPM-Llama3-V 2.5**ï¼Œæˆ‘ä»¬ä¹Ÿæ­£ç§¯ææ¨è¿›å°†è¿™äº›åŠŸèƒ½åˆå¹¶åˆ° llama.cpp & ollama å®˜æ–¹ä»“åº“ï¼Œæ•¬è¯·å…³æ³¨ï¼
* [2024.05.28] ğŸ’« æˆ‘ä»¬ç°åœ¨æ”¯æŒ MiniCPM-Llama3-V 2.5 çš„ LoRA å¾®è°ƒï¼Œæ›´å¤šå†…å­˜ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune#model-fine-tuning-memory-usage-statistics)æ‰¾åˆ°ã€‚
* [2024.05.23] ğŸ” æˆ‘ä»¬æ·»åŠ äº†Phi-3-vision-128k-instruct ä¸ MiniCPM-Llama3-V 2.5çš„å…¨é¢å¯¹æ¯”ï¼ŒåŒ…æ‹¬åŸºå‡†æµ‹è¯•è¯„ä¼°ã€å¤šè¯­è¨€èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ ğŸŒŸğŸ“ŠğŸŒğŸš€ã€‚ç‚¹å‡»[è¿™é‡Œ](./docs/compare_with_phi-3_vision.md)æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ã€‚
* [2024.05.23] ğŸ”¥ğŸ”¥ğŸ”¥ MiniCPM-V åœ¨ GitHub Trending å’Œ Hugging Face Trending ä¸Šç™»é¡¶ï¼MiniCPM-Llama3-V 2.5 Demo è¢« Hugging Face çš„ Gradio å®˜æ–¹è´¦æˆ·æ¨èï¼Œæ¬¢è¿ç‚¹å‡»[è¿™é‡Œ](https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5)ä½“éªŒï¼


<br>


* [2024.06.03] ç°åœ¨ï¼Œä½ å¯ä»¥åˆ©ç”¨å¤šå¼ ä½æ˜¾å­˜æ˜¾å¡ï¼ˆ12G/16Gï¼‰è¿›è¡ŒGPUä¸²è¡Œæ¨ç†ã€‚è¯¦æƒ…è¯·å‚è§è¯¥[æ–‡æ¡£](https://github.com/OpenBMB/MiniCPM-V/blob/main/docs/inference_on_multiple_gpus.md)é…ç½®ã€‚
* [2024.05.25] MiniCPM-Llama3-V 2.5 [æ”¯æŒæµå¼è¾“å‡ºå’Œè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5#usage)äº†ï¼Œæ¬¢è¿è¯•ç”¨!
* [2024.05.24] æˆ‘ä»¬å¼€æºäº† MiniCPM-Llama3-V 2.5 [gguf](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf)ï¼Œæ”¯æŒ [llama.cpp](#llamacpp-éƒ¨ç½²) æ¨ç†ï¼å®ç°ç«¯ä¾§ 6-8 tokens/s çš„æµç•…è§£ç ï¼Œæ¬¢è¿è¯•ç”¨ï¼
* [2024.05.20] æˆ‘ä»¬å¼€æºäº† MiniCPM-Llama3-V 2.5ï¼Œå¢å¼ºäº† OCR èƒ½åŠ›ï¼Œæ”¯æŒ 30 å¤šç§è¯­è¨€ï¼Œå¹¶é¦–æ¬¡åœ¨ç«¯ä¾§å®ç°äº† GPT-4V çº§çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼æˆ‘ä»¬æä¾›äº†[é«˜æ•ˆæ¨ç†](#æ‰‹æœºç«¯éƒ¨ç½²)å’Œ[ç®€æ˜“å¾®è°ƒ](./finetune/readme.md)çš„æ”¯æŒï¼Œæ¬¢è¿è¯•ç”¨ï¼
* [2024.04.23] æˆ‘ä»¬å¢åŠ äº†MiniCPM-V 2.0å¯¹ [vLLM](#vllm) çš„æ”¯æŒï¼Œæ¬¢è¿ä½“éªŒï¼
* [2024.04.18] æˆ‘ä»¬åœ¨ HuggingFace Space æ–°å¢äº† MiniCPM-V 2.0 çš„ [demo](https://huggingface.co/spaces/openbmb/MiniCPM-V-2)ï¼Œæ¬¢è¿ä½“éªŒï¼
* [2024.04.17] MiniCPM-V 2.0 ç°åœ¨æ”¯æŒç”¨æˆ·éƒ¨ç½²æœ¬åœ° [WebUI Demo](#æœ¬åœ°webui-demoéƒ¨ç½²) äº†ï¼Œæ¬¢è¿è¯•ç”¨!
* [2024.04.15] MiniCPM-V 2.0 ç°åœ¨å¯ä»¥é€šè¿‡ SWIFT æ¡†æ¶ [å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-v-2æœ€ä½³å®è·µ.md) äº†ï¼Œæ”¯æŒæµå¼è¾“å‡º!
* [2024.04.12] æˆ‘ä»¬å¼€æºäº† MiniCPM-V 2.0ï¼Œè¯¥æ¨¡å‹åˆ·æ–°äº† OCRBench å¼€æºæ¨¡å‹æœ€ä½³æˆç»©ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Šæ¯”è‚© Gemini Proï¼ŒåŒæ—¶è¿˜åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ <a href="https://rank.opencompass.org.cn/leaderboard-multimodal">OpenCompass</a> æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 10Bã€CogVLM-Chat 17B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼ç‚¹å‡»<a href="https://openbmb.vercel.app/minicpm-v-2">è¿™é‡Œ</a>æŸ¥çœ‹ MiniCPM-V 2.0 æŠ€æœ¯åšå®¢ã€‚
* [2024.03.14] MiniCPM-V ç°åœ¨æ”¯æŒ SWIFT æ¡†æ¶ä¸‹çš„[å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-væœ€ä½³å®è·µ.md)äº†ï¼Œæ„Ÿè°¢ [Jintao](https://github.com/Jintao-Huang) çš„è´¡çŒ®ï¼
* [2024.03.01] MiniCPM-V ç°åœ¨æ”¯æŒåœ¨ Mac ç”µè„‘ä¸Šè¿›è¡Œéƒ¨ç½²ï¼
* [2024.02.01] æˆ‘ä»¬å¼€æºäº† MiniCPM-V å’Œ OmniLMM-12Bï¼Œåˆ†åˆ«å¯ä»¥æ”¯æŒé«˜æ•ˆçš„ç«¯ä¾§éƒ¨ç½²å’ŒåŒè§„æ¨¡é¢†å…ˆçš„å¤šæ¨¡æ€èƒ½åŠ›ï¼


## ç›®å½• <!-- omit in toc -->

- [MiniCPM-Llama3-V 2.5](#minicpm-llama3-v-25)
- [MiniCPM-V 2.0](#minicpm-v-20)
- [Demo](#demo)
- [å®‰è£…](#å®‰è£…)
- [æ¨ç†](#æ¨ç†)
  - [æ¨¡å‹åº“](#æ¨¡å‹åº“)
  - [å¤šè½®å¯¹è¯](#å¤šè½®å¯¹è¯)
  - [Mac æ¨ç†](#mac-æ¨ç†)
  - [æ‰‹æœºç«¯éƒ¨ç½²](#æ‰‹æœºç«¯éƒ¨ç½²)
  - [æœ¬åœ°WebUI Demoéƒ¨ç½²](#æœ¬åœ°webui-demoéƒ¨ç½²)
  - [llama.cpp éƒ¨ç½²](#llamacpp-éƒ¨ç½²)
  - [vLLM éƒ¨ç½² ](#vllm-éƒ¨ç½²-)
- [å¾®è°ƒ](#å¾®è°ƒ)
- [æœªæ¥è®¡åˆ’](#æœªæ¥è®¡åˆ’)
- [ğŸŒŸ Star History](#-star-history)
- [å¼•ç”¨](#å¼•ç”¨)


## MiniCPM-Llama3-V 2.5
**MiniCPM-Llama3-V 2.5** æ˜¯ MiniCPM-V ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬æ¨¡å‹ï¼ŒåŸºäº SigLip-400M å’ŒÂ Llama3-8B-Instruct æ„å»ºï¼Œå…± 8B å‚æ•°é‡ï¼Œç›¸è¾ƒäº MiniCPM-V 2.0 æ€§èƒ½å–å¾—è¾ƒå¤§å¹…åº¦æå‡ã€‚MiniCPM-Llama3-V 2.5 å€¼å¾—å…³æ³¨çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- ğŸ”¥ **é¢†å…ˆçš„æ€§èƒ½ã€‚**
  MiniCPM-Llama3-V 2.5 åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ OpenCompass æ¦œå•ä¸Šå¹³å‡å¾—åˆ† 65.1ï¼Œ**ä»¥ 8B é‡çº§çš„å¤§å°è¶…è¿‡äº† GPT-4V-1106ã€Gemini Proã€Claude 3ã€Qwen-VL-Max ç­‰ä¸»æµå•†ç”¨é—­æºå¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼Œå¤§å¹…è¶…è¶ŠåŸºäºLlama 3æ„å»ºçš„å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚

- ğŸ’ª **ä¼˜ç§€çš„ OCR èƒ½åŠ›ã€‚**
  MiniCPM-Llama3-V 2.5 å¯æ¥å— 180 ä¸‡åƒç´ çš„ä»»æ„å®½é«˜æ¯”å›¾åƒè¾“å…¥ï¼Œ**OCRBench å¾—åˆ†è¾¾åˆ° 725ï¼Œè¶…è¶Š GPT-4oã€GPT-4Vã€Gemini Proã€Qwen-VL-Max ç­‰å•†ç”¨é—­æºæ¨¡å‹**ï¼Œè¾¾åˆ°æœ€ä½³æ°´å¹³ã€‚åŸºäºè¿‘æœŸç”¨æˆ·åé¦ˆå»ºè®®ï¼ŒMiniCPM-Llama3-V 2.5 å¢å¼ºäº†å…¨æ–‡ OCR ä¿¡æ¯æå–ã€è¡¨æ ¼å›¾åƒè½¬ markdown ç­‰é«˜é¢‘å®ç”¨èƒ½åŠ›ï¼Œå¹¶ä¸”è¿›ä¸€æ­¥åŠ å¼ºäº†æŒ‡ä»¤è·Ÿéšã€å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå¸¦æ¥æ›´å¥½çš„å¤šæ¨¡æ€äº¤äº’ä½“æ„Ÿã€‚

- ğŸ† **å¯ä¿¡è¡Œä¸ºã€‚** 
  å€ŸåŠ©æœ€æ–°çš„ [RLAIF-V](https://github.com/RLHF-V/RLAIF-V/) å¯¹é½æŠ€æœ¯ï¼ˆ[RLHF-V](https://github.com/RLHF-V/) [CVPR'24]ç³»åˆ—çš„æœ€æ–°æŠ€æœ¯ï¼‰ï¼ŒMiniCPM-Llama3-V 2.5 å…·æœ‰æ›´åŠ å¯ä¿¡çš„å¤šæ¨¡æ€è¡Œä¸ºï¼Œåœ¨Â Object HalBench çš„å¹»è§‰ç‡é™ä½åˆ°äº† **10.3%**ï¼Œæ˜¾è‘—ä½äº GPT-4V-1106 (13.6%)ï¼Œè¾¾åˆ°å¼€æºç¤¾åŒºæœ€ä½³æ°´å¹³ã€‚[æ•°æ®é›†å·²å‘å¸ƒ](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)ã€‚

- ğŸŒ **å¤šè¯­è¨€æ”¯æŒã€‚**
  å¾—ç›Šäº Llama 3 å¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›å’Œ VisCPM çš„è·¨è¯­è¨€æ³›åŒ–æŠ€æœ¯ï¼ŒMiniCPM-Llama3-V 2.5Â åœ¨ä¸­è‹±åŒè¯­å¤šæ¨¡æ€èƒ½åŠ›çš„åŸºç¡€ä¸Šï¼Œä»…é€šè¿‡å°‘é‡ç¿»è¯‘çš„å¤šæ¨¡æ€æ•°æ®çš„æŒ‡ä»¤å¾®è°ƒï¼Œé«˜æ•ˆæ³›åŒ–æ”¯æŒäº†**å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ã€æ„å¤§åˆ©è¯­ã€éŸ©è¯­ç­‰ 30+ ç§è¯­è¨€**çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼Œå¹¶è¡¨ç°å‡ºäº†è‰¯å¥½çš„å¤šè¯­è¨€å¤šæ¨¡æ€å¯¹è¯æ€§èƒ½ã€‚[æŸ¥çœ‹æ‰€æœ‰æ”¯æŒè¯­è¨€](./assets/minicpm-llama-v-2-5_languages.md)

- ğŸš€ **é«˜æ•ˆéƒ¨ç½²ã€‚**
  MiniCPM-Llama3-V 2.5 è¾ƒä¸ºç³»ç»Ÿåœ°é€šè¿‡**æ¨¡å‹é‡åŒ–ã€CPUã€NPUã€ç¼–è¯‘ä¼˜åŒ–**ç­‰é«˜æ•ˆåŠ é€ŸæŠ€æœ¯ï¼Œå®ç°é«˜æ•ˆçš„ç»ˆç«¯è®¾å¤‡éƒ¨ç½²ã€‚å¯¹äºé«˜é€šèŠ¯ç‰‡çš„ç§»åŠ¨æ‰‹æœºï¼Œæˆ‘ä»¬é¦–æ¬¡å°† NPU åŠ é€Ÿæ¡†æ¶ QNN æ•´åˆè¿›äº† llama.cppã€‚ç»è¿‡ç³»ç»Ÿä¼˜åŒ–åï¼ŒMiniCPM-Llama3-V 2.5 å®ç°äº†å¤šæ¨¡æ€å¤§æ¨¡å‹ç«¯ä¾§**è¯­è¨€è§£ç é€Ÿåº¦ 3 å€åŠ é€Ÿ**ã€**å›¾åƒç¼–ç  150 å€åŠ é€Ÿ**çš„å·¨å¤§æå‡ã€‚

- ğŸ’« **æ˜“äºä½¿ç”¨ã€‚**
  MiniCPM-Llama3-V 2.5 å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è½»æ¾ä½¿ç”¨ï¼šï¼ˆ1ï¼‰[llama.cpp](https://github.com/OpenBMB/llama.cpp/blob/minicpm-v2.5/examples/minicpmv/README.md) å’Œ [ollama](https://github.com/OpenBMB/ollama/tree/minicpm-v2.5/examples/minicpm-v2.5) æ”¯æŒåœ¨æœ¬åœ°è®¾å¤‡ä¸Šè¿›è¡Œé«˜æ•ˆçš„ CPU æ¨ç†ï¼›ï¼ˆ2ï¼‰æä¾› 16 ç§å°ºå¯¸çš„ [GGUF](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf) æ ¼å¼é‡åŒ–æ¨¡å‹ï¼›ï¼ˆ3ï¼‰ä»…éœ€ 2 å¼  V100 GPU å³å¯è¿›è¡Œé«˜æ•ˆçš„ [LoRA](https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune#lora-finetuning) å¾®è°ƒï¼›ï¼ˆ	4ï¼‰æ”¯æŒ[æµå¼è¾“å‡º](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5#usage)ï¼›ï¼ˆ5ï¼‰å¿«é€Ÿæ­å»º [Gradio](https://github.com/OpenBMB/MiniCPM-V/blob/main/web_demo_2.5.py) å’Œ [Streamlit](https://github.com/OpenBMB/MiniCPM-V/blob/main/web_demo_streamlit-2_5.py) æœ¬åœ° WebUI demoï¼›ï¼ˆ	6.ï¼‰[HuggingFace Spaces](https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5) äº¤äº’å¼ demoã€‚

### æ€§èƒ½è¯„ä¼° <!-- omit in toc -->

<div align="center">
    <img src="assets/MiniCPM-Llama3-V-2.5-peformance.png" width="66%" />
</div>
<details>
<summary>TextVQA, DocVQA, OCRBench, OpenCompass MultiModal Avg Score, MME, MMBench, MMMU, MathVista, LLaVA Bench, RealWorld QA, Object HalBenchä¸Šçš„è¯¦ç»†è¯„æµ‹ç»“æœã€‚ </summary>
<div align="center">

<table style="margin: 0px auto;">
    <thead>
        <tr>
            <th align="left">Model</th>
            <th>Size</th>
            <th>OCRBench</th>
            <th>TextVQA val</th>
            <th>DocVQA test</th>
            <th>Open-Compass</th>
            <th>MME</th>
            <th>MMB test (en)</th>
            <th>MMB test (cn)</th>
            <th>MMMU val</th>
            <th>Math-Vista</th>
            <th>LLaVA Bench</th>
            <th>RealWorld QA</th>
            <th>Object HalBench</th>
        </tr>
    </thead>
            <tbody align="center">
        <tr>
            <td colspan="14" align="left"><strong>Proprietary</strong></td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">Gemini Pro</td>
            <td>-</td>
            <td>680</td>
            <td>74.6</td>
            <td>88.1</td>
            <td>62.9</td>
            <td>2148.9</td>
            <td>73.6</td>
            <td>74.3</td>
            <td>48.9</td>
            <td>45.8</td>
            <td>79.9</td>
            <td>60.4</td>
            <td>-</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">GPT-4V (2023.11.06)</td>
            <td>-</td>
            <td>645</td>
            <td>78.0</td>
            <td>88.4</td>
            <td>63.5</td>
            <td>1771.5</td>
            <td>77.0</td>
            <td>74.4</td>
            <td>53.8</td>
            <td>47.8</td>
            <td>93.1</td>
            <td>63.0</td>
            <td>86.4</td>
        </tr>
        <tr>
            <td colspan="14" align="left"><strong>Open-source</strong></td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">Mini-Gemini</td>
            <td>2.2B</td>
            <td>-</td>
            <td>56.2</td>
            <td>34.2*</td>
            <td>-</td>
            <td>1653.0</td>
            <td>-</td>
            <td>-</td>
            <td>31.7</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">Qwen-VL-Chat</td>
            <td>9.6B</td>
            <td>488</td>
            <td>61.5</td>
            <td>62.6</td>
            <td>51.6</td>
            <td>1860.0</td>
            <td>61.8</td>
            <td>56.3</td>
            <td>37.0</td>
            <td>33.8</td>
            <td>67.7</td>
            <td>49.3</td>
            <td>56.2</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">DeepSeek-VL-7B</td>
            <td>7.3B</td>
            <td>435</td>
            <td>64.7*</td>
            <td>47.0*</td>
            <td>54.6</td>
            <td>1765.4</td>
            <td>73.8</td>
            <td>71.4</td>
            <td>38.3</td>
            <td>36.8</td>
            <td>77.8</td>
            <td>54.2</td>
            <td>-</td>
        </tr>        
        <tr>
            <td nowrap="nowrap" align="left">Yi-VL-34B</td>
            <td>34B</td>
            <td>290</td>
            <td>43.4*</td>
            <td>16.9*</td>
            <td>52.2</td>
            <td><strong>2050.2</strong></td>
            <td>72.4</td>
            <td>70.7</td>
            <td>45.1</td>
            <td>30.7</td>
            <td>62.3</td>
            <td>54.8</td>
            <td>79.3</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">CogVLM-Chat</td>
            <td>17.4B</td>
            <td>590</td>
            <td>70.4</td>
            <td>33.3*</td>
            <td>54.2</td>
            <td>1736.6</td>
            <td>65.8</td>
            <td>55.9</td>
            <td>37.3</td>
            <td>34.7</td>
            <td>73.9</td>
            <td>60.3</td>
            <td>73.6</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">TextMonkey</td>
            <td>9.7B</td>
            <td>558</td>
            <td>64.3</td>
            <td>66.7</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
        </tr>
        <tr>
          <td nowrap="nowrap" align="left">Idefics2</td>
          <td>8.0B</td>
          <td>-</td>
          <td>73.0</td>
          <td>74.0</td>
          <td>57.2</td>
          <td>1847.6</td>
          <td>75.7</td>
          <td>68.6</td>
          <td>45.2</td>
          <td>52.2</td>
          <td>49.1</td>
          <td>60.7</td>
          <td>-</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">Bunny-LLama-3-8B</td>
            <td>8.4B</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>54.3</td>
            <td>1920.3</td>
            <td>77.0</td>
            <td>73.9</td>
            <td>41.3</td>
            <td>31.5</td>
            <td>61.2</td>
            <td>58.8</td>
            <td>-</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">LLaVA-NeXT Llama-3-8B</td>
            <td>8.4B</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>1971.5</td>
            <td>-</td>
            <td>-</td>
            <td>41.7</td>
            <td>-</td>
            <td>80.1</td>
            <td>60.0</td>
            <td>-</td>
        </tr>
        <tr>
            <td nowrap="nowrap" align="left">Phi-3-vision-128k-instruct</td>
            <td>4.2B</td>
            <td>639*</td>
            <td>70.9</td>
            <td>-</td>
            <td>-</td>
            <td>1537.5*</td>
            <td>-</td>
            <td>-</td>
            <td>40.4</td>
            <td>44.5</td>
            <td>64.2*</td>
            <td>58.8*</td>
            <td>-</td>
        </tr>
        <tr style="background-color: #e6f2ff;">
            <td nowrap="nowrap" align="left">MiniCPM-V 1.0</td>
            <td>2.8B</td>
            <td>366</td>
            <td>60.6</td>
            <td>38.2</td>
            <td>47.5</td>
            <td>1650.2</td>
            <td>64.1</td>
            <td>62.6</td>
            <td>38.3</td>
            <td>28.9</td>
            <td>51.3</td>
            <td>51.2</td>
            <td>78.4</td>
        </tr>
        <tr style="background-color: #e6f2ff;">
            <td nowrap="nowrap" align="left">MiniCPM-V 2.0</td>
            <td>2.8B</td>
            <td>605</td>
            <td>74.1</td>
            <td>71.9</td>
            <td>54.5</td>
            <td>1808.6</td>
            <td>69.1</td>
            <td>66.5</td>
            <td>38.2</td>
            <td>38.7</td>
            <td>69.2</td>
            <td>55.8</td>
            <td>85.5</td>
        </tr>
        <tr style="background-color: #e6f2ff;">
            <td nowrap="nowrap" align="left">MiniCPM-Llama3-V 2.5</td>
            <td>8.5B</td>
            <td><strong>725</strong></td>
            <td><strong>76.6</strong></td>
            <td><strong>84.8</strong></td>
            <td><strong>65.1</strong></td>
            <td>2024.6</td>
            <td><strong>77.2</strong></td>
            <td><strong>74.2</strong></td>
            <td><strong>45.8</strong></td>
            <td><strong>54.3</strong></td>
            <td><strong>86.7</strong></td>
            <td><strong>63.5</strong></td>
            <td><strong>89.7</strong></td>
        </tr>
    </tbody>
</table>

</div>
* æ­£å¼å¼€æºæ¨¡å‹æƒé‡çš„è¯„æµ‹ç»“æœã€‚
</details>

<div align="center">
    <img src="assets/llavabench_compare_3.png" width="80%" />
    <br>
    å¤šè¯­è¨€LLaVA Benchè¯„æµ‹ç»“æœ
</div>


### å…¸å‹ç¤ºä¾‹ <!-- omit in toc -->
<table align="center">
    <p align="center">
      <img src="assets/minicpmv-llama3-v2.5/cases_all.png" width=95%/>
    </p>
</table>

æˆ‘ä»¬å°† MiniCPM-Llama3-V 2.5 éƒ¨ç½²åœ¨å°ç±³ 14 Pro ä¸Šï¼Œå¹¶å½•åˆ¶äº†ä»¥ä¸‹æ¼”ç¤ºè§†é¢‘ã€‚

<table align="center">
    <p align="center">
      <img src="assets/gif_cases/ticket.gif" width=32%/>
      <img src="assets/gif_cases/meal_plan.gif" width=32%/>
    </p>
</table>

<table align="center">
    <p align="center" width=80%>
      <img src="assets/gif_cases/1-4.gif" width=72%/>
    </p>
</table>

## MiniCPM-V 2.0

<details>
<summary>æŸ¥çœ‹ MiniCPM-V 2.0 çš„è¯¦ç»†ä¿¡æ¯</summary>

**MiniCPM-V 2.0**å¯ä»¥é«˜æ•ˆéƒ¨ç½²åˆ°ç»ˆç«¯è®¾å¤‡ã€‚è¯¥æ¨¡å‹åŸºäº SigLip-400M å’Œ [MiniCPM-2.4B](https://github.com/OpenBMB/MiniCPM/)æ„å»ºï¼Œé€šè¿‡perceiver resamplerè¿æ¥ã€‚å…¶ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- ğŸ”¥ **ä¼˜ç§€çš„æ€§èƒ½ã€‚**

  MiniCPM-V 2.0 åœ¨å¤šä¸ªæµ‹è¯•åŸºå‡†ï¼ˆå¦‚ OCRBench, TextVQA, MME, MMB, MathVista ç­‰ï¼‰ä¸­å®ç°äº† 7B ä»¥ä¸‹æ¨¡å‹çš„**æœ€ä½³æ€§èƒ½**ã€‚**åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ OpenCompass æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 9.6Bã€CogVLM-Chat 17.4B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹**ã€‚MiniCPM-V 2.0 è¿˜å±•ç°å‡º**é¢†å…ˆçš„ OCR èƒ½åŠ›**ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Š**æ¥è¿‘ Gemini Pro**ï¼ŒOCRBench å¾—åˆ†è¾¾åˆ°**å¼€æºæ¨¡å‹ç¬¬ä¸€**ã€‚
  

- ğŸ† **å¯ä¿¡è¡Œä¸ºã€‚** 

  å¤šæ¨¡æ€å¤§æ¨¡å‹æ·±å—å¹»è§‰é—®é¢˜å›°æ‰°ï¼Œæ¨¡å‹ç»å¸¸ç”Ÿæˆå’Œå›¾åƒä¸­çš„äº‹å®ä¸ç¬¦çš„æ–‡æœ¬ã€‚MiniCPM-V 2.0 æ˜¯ **ç¬¬ä¸€ä¸ªé€šè¿‡å¤šæ¨¡æ€ RLHF å¯¹é½çš„ç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ˆå€ŸåŠ© [RLHF-V](https://rlhf-v.github.io/) [CVPR'24] ç³»åˆ—æŠ€æœ¯ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ [Object HalBench](https://arxiv.org/abs/2312.00849) è¾¾åˆ°**å’Œ GPT-4V ç›¸ä»¿**çš„æ€§èƒ½ã€‚


- ğŸŒŸ **é«˜æ¸…å›¾åƒé«˜æ•ˆç¼–ç ã€‚**

  MiniCPM-V 2.0 å¯ä»¥æ¥å— **180 ä¸‡åƒç´ çš„ä»»æ„é•¿å®½æ¯”å›¾åƒè¾“å…¥**ï¼ˆåŸºäºæœ€æ–°çš„[LLaVA-UHD](https://arxiv.org/pdf/2403.11703.pdf) æŠ€æœ¯ï¼‰ï¼Œè¿™ä½¿å¾—æ¨¡å‹å¯ä»¥æ„ŸçŸ¥åˆ°å°ç‰©ä½“ã€å¯†é›†æ–‡å­—ç­‰æ›´åŠ ç»†ç²’åº¦çš„è§†è§‰ä¿¡æ¯ã€‚ 


- âš¡ï¸ **é«˜æ•ˆéƒ¨ç½²ã€‚**

  MiniCPM-V 2.0 å¯ä»¥**é«˜æ•ˆéƒ¨ç½²åœ¨å¤§å¤šæ•°æ¶ˆè´¹çº§æ˜¾å¡å’Œä¸ªäººç”µè„‘ä¸Š**ï¼ŒåŒ…æ‹¬**ç§»åŠ¨æ‰‹æœºç­‰ç»ˆç«¯è®¾å¤‡**ã€‚åœ¨è§†è§‰ç¼–ç æ–¹é¢ï¼Œæˆ‘ä»¬é€šè¿‡perceiver resamplerå°†å›¾åƒè¡¨ç¤ºå‹ç¼©ä¸ºæ›´å°‘çš„ tokenã€‚è¿™ä½¿å¾— MiniCPM-V 2.0 å³ä¾¿æ˜¯**é¢å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä¹Ÿèƒ½å ç”¨è¾ƒä½çš„å­˜å‚¨å¹¶å±•ç°ä¼˜ç§€çš„æ¨ç†é€Ÿåº¦**ã€‚

- ğŸ™Œ **åŒè¯­æ”¯æŒã€‚**

  MiniCPM-V 2.0 **æä¾›é¢†å…ˆçš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€èƒ½åŠ›æ”¯æŒ**ã€‚
  è¯¥èƒ½åŠ›é€šè¿‡ [VisCPM](https://arxiv.org/abs/2308.12038) [ICLR'24] è®ºæ–‡ä¸­æå‡ºçš„å¤šæ¨¡æ€èƒ½åŠ›çš„è·¨è¯­è¨€æ³›åŒ–æŠ€æœ¯å®ç°ã€‚

### å…¸å‹ç¤ºä¾‹ <!-- omit in toc -->


<table align="center">
    <p align="center">
      <img src="assets/minicpmv2-cases_2.png" width=95%/>
    </p>
</table>

æˆ‘ä»¬å°† MiniCPM-V 2.0 éƒ¨ç½²åœ¨å°ç±³ 14 Pro ä¸Šï¼Œå¹¶å½•åˆ¶äº†ä»¥ä¸‹æ¼”ç¤ºè§†é¢‘ï¼Œæœªç»ä»»ä½•è§†é¢‘å‰ªè¾‘ã€‚

<table align="center">
    <p align="center">
      <img src="assets/gif_cases/station.gif" width=36%/>
      <img src="assets/gif_cases/london_car.gif" width=36%/>
    </p>
</table>

</details>


<a id='legacy-models'></a>

## å†å²ç‰ˆæœ¬æ¨¡å‹  <!-- omit in toc -->


| æ¨¡å‹                | ä»‹ç»ä¿¡æ¯å’Œä½¿ç”¨æ•™ç¨‹       |
|:----------------------|:-------------------:|
| MiniCPM-V 1.0  | [æ–‡æ¡£](./minicpm_v1.md)   | 
| OmniLMM-12B  | [æ–‡æ¡£](./omnilmm.md)   |  


## Demo

æˆ‘ä»¬æä¾›ç”± Hugging Face [Gradio](https://github.com/gradio-app/gradio) æ”¯æŒçš„åœ¨çº¿å’Œæœ¬åœ° Demoã€‚Gradio æ˜¯ç›®å‰æœ€æµè¡Œçš„æ¨¡å‹éƒ¨ç½²æ¡†æ¶ï¼Œæ”¯æŒæµå¼è¾“å‡ºã€è¿›åº¦æ¡ã€process bars å’Œå…¶ä»–å¸¸ç”¨åŠŸèƒ½ã€‚

### Online Demo <!-- omit in toc --> 

æ¬¢è¿è¯•ç”¨ Hugging Face Spaces ä¸Šçš„ [MiniCPM-Llama3-V 2.5](https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5) ï½œ [MiniCPM-V 2.0](https://huggingface.co/spaces/openbmb/MiniCPM-V-2) Online Demoã€‚

### æœ¬åœ° WebUI Demo <!-- omit in toc --> 

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è½»æ¾æ„å»ºè‡ªå·±çš„æœ¬åœ° WebUI Demoã€‚

```shell
pip install -r requirements.txt
```

```shell
# å¯¹äº NVIDIA GPUï¼Œè¯·è¿è¡Œï¼š
python web_demo_2.5.py --device cuda

# å¯¹äºæ­è½½ MPS çš„ Macï¼ˆApple èŠ¯ç‰‡æˆ– AMD GPUï¼‰ï¼Œè¯·è¿è¡Œï¼š
PYTORCH_ENABLE_MPS_FALLBACK=1 python web_demo_2.5.py --device mps
```



## å®‰è£…

1. å…‹éš†æˆ‘ä»¬çš„ä»“åº“å¹¶è·³è½¬åˆ°ç›¸åº”ç›®å½•

```bash
git clone https://github.com/OpenBMB/MiniCPM-V.git
cd MiniCPM-V
```

1. åˆ›å»º conda ç¯å¢ƒ

```Shell
conda create -n MiniCPMV python=3.10 -y
conda activate MiniCPMV
```

3. å®‰è£…ä¾èµ–

```shell
pip install -r requirements.txt
```

## æ¨ç†

### æ¨¡å‹åº“

| æ¨¡å‹           | è®¾å¤‡ | èµ„æº     | &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ç®€ä»‹       | ä¸‹è½½é“¾æ¥ |
|:--------------|:-:|:----------:|:-------------------|:---------------:|
| MiniCPM-Llama3-V 2.5| GPU | 19 GB  | æœ€æ–°ç‰ˆæœ¬ï¼Œæä¾›æœ€ä½³çš„ç«¯ä¾§å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚   |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5/) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-Llama3-V-2_5) |
| MiniCPM-Llama3-V 2.5 gguf| CPU  | 5 GB | gguf ç‰ˆæœ¬ï¼Œæ›´ä½çš„å†…å­˜å ç”¨å’Œæ›´é«˜çš„æ¨ç†æ•ˆç‡ã€‚  |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-Llama3-V-2_5-gguf) |
| MiniCPM-Llama3-V 2.5 int4 | GPU | 8 GB | int4é‡åŒ–ç‰ˆï¼Œæ›´ä½æ˜¾å­˜å ç”¨ã€‚   |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-int4/) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-Llama3-V-2_5-int4) |
| MiniCPM-V 2.0 | GPU | 8 GB  | è½»é‡çº§ç‰ˆæœ¬ï¼Œå¹³è¡¡è®¡ç®—å¼€é”€å’Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚   |  [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-V-2) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-V-2) |
| MiniCPM-V 1.0 | GPU | 7 GB | æœ€è½»é‡ç‰ˆæœ¬ï¼Œ æä¾›æœ€å¿«çš„æ¨ç†é€Ÿåº¦ã€‚    |   [ğŸ¤—](https://huggingface.co/openbmb/MiniCPM-V) &nbsp;&nbsp; [<img src="./assets/modelscope_logo.png" width="20px"></img>](https://modelscope.cn/models/OpenBMB/MiniCPM-V) |

æ›´å¤š[å†å²ç‰ˆæœ¬æ¨¡å‹](#legacy-models)

### å¤šè½®å¯¹è¯

è¯·å‚è€ƒä»¥ä¸‹ä»£ç è¿›è¡Œæ¨ç†ã€‚

<div align="center">
<img src="assets/airplane.jpeg" width="500px">
</div>


```python
from chat import MiniCPMVChat, img2base64
import torch
import json

torch.manual_seed(0)

chat_model = MiniCPMVChat('openbmb/MiniCPM-Llama3-V-2_5')

im_64 = img2base64('./assets/airplane.jpeg')

# First round chat 
msgs = [{"role": "user", "content": "Tell me the model of this aircraft."}]

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.chat(inputs)
print(answer)

# Second round chat 
# pass history context of multi-turn conversation
msgs.append({"role": "assistant", "content": answer})
msgs.append({"role": "user", "content": "Introduce something about Airbus A380."})

inputs = {"image": im_64, "question": json.dumps(msgs)}
answer = chat_model.chat(inputs)
print(answer)
```

å¯ä»¥å¾—åˆ°ä»¥ä¸‹è¾“å‡º:

```
"The aircraft in the image is an Airbus A380, which can be identified by its large size, double-deck structure, and the distinctive shape of its wings and engines. The A380 is a wide-body aircraft known for being the world's largest passenger airliner, designed for long-haul flights. It has four engines, which are characteristic of large commercial aircraft. The registration number on the aircraft can also provide specific information about the model if looked up in an aviation database."

"The Airbus A380 is a double-deck, wide-body, four-engine jet airliner made by Airbus. It is the world's largest passenger airliner and is known for its long-haul capabilities. The aircraft was developed to improve efficiency and comfort for passengers traveling over long distances. It has two full-length passenger decks, which can accommodate more passengers than a typical single-aisle airplane. The A380 has been operated by airlines such as Lufthansa, Singapore Airlines, and Emirates, among others. It is widely recognized for its unique design and significant impact on the aviation industry."
```




### Mac æ¨ç†
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ MiniCPM-Llama3-V 2.5 / MiniCPM-V 2.0 åŸºäºMac MPSè¿è¡Œ (Apple silicon æˆ– AMD GPUs)çš„ç¤ºä¾‹ã€‚ </summary>

```python
# test.py    Need more than 16GB memory to run.
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True, low_cpu_mem_usage=True)
model = model.to(device='mps')

tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True)
model.eval()

image = Image.open('./assets/hk_OCR.jpg').convert('RGB')
question = 'Where is this photo taken?'
msgs = [{'role': 'user', 'content': question}]

answer, context, _ = model.chat(
    image=image,
    msgs=msgs,
    context=None,
    tokenizer=tokenizer,
    sampling=True
)
print(answer)
```
è¿è¡Œ:
```shell
PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py
```
</details>


### æ‰‹æœºç«¯éƒ¨ç½²
MiniCPM-Llama3-V 2.5 å’Œ MiniCPM-V 2.0 å¯è¿è¡Œåœ¨Androidæ‰‹æœºä¸Šï¼Œç‚¹å‡»[MiniCPM-Llama3-V 2.5](http://minicpm.modelbest.cn/android/modelbest-release-20240528_182155.apk) / [MiniCPM-V 2.0](https://github.com/OpenBMB/mlc-MiniCPM)å®‰è£…apkä½¿ç”¨; 

### æœ¬åœ°WebUI Demoéƒ¨ç½²
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹æœ¬åœ°WebUI demo åœ¨ NVIDIA GPUã€Macç­‰ä¸åŒè®¾å¤‡éƒ¨ç½²æ–¹æ³• </summary>
  
```shell
pip install -r requirements.txt
```
  
```shell
# For NVIDIA GPUs, run:
python web_demo_2.5.py --device cuda

# For Mac with MPS (Apple silicon or AMD GPUs), run:
PYTORCH_ENABLE_MPS_FALLBACK=1 python web_demo_2.5.py --device mps
```
</details>

### llama.cpp éƒ¨ç½²<a id="llamacpp-éƒ¨ç½²"></a>
MiniCPM-Llama3-V 2.5 ç°åœ¨æ”¯æŒllama.cppå•¦! ç”¨æ³•è¯·å‚è€ƒæˆ‘ä»¬çš„fork [llama.cpp](https://github.com/OpenBMB/llama.cpp/tree/minicpm-v2.5/examples/minicpmv)ï¼Œ åœ¨æ‰‹æœºä¸Šå¯ä»¥æ”¯æŒ 6~8 token/s çš„æµç•…æ¨ç†ï¼ˆæµ‹è¯•ç¯å¢ƒï¼šXiaomi 14 pro + Snapdragon 8 Gen 3ï¼‰ã€‚

### vLLM éƒ¨ç½² <a id='vllm'></a>
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ MiniCPM-V 2.0 åˆ©ç”¨vLLM éƒ¨ç½²è¿è¡Œçš„æ–¹æ³•ï¼ˆMiniCPM-Llama3-V 2.5 æ”¯æŒvLLMå°†åœ¨è¿‘æœŸæ¨å‡ºï¼‰</summary>
ç”±äºæˆ‘ä»¬å¯¹ vLLM æäº¤çš„ PR è¿˜åœ¨ review ä¸­ï¼Œå› æ­¤ç›®å‰æˆ‘ä»¬ fork äº†ä¸€ä¸ª vLLM ä»“åº“ä»¥ä¾›æµ‹è¯•ä½¿ç”¨ã€‚

1. é¦–å…ˆå…‹éš†æˆ‘ä»¬ fork çš„ vLLM åº“:
```shell
git clone https://github.com/OpenBMB/vllm.git
```
2. å®‰è£… vLLM åº“:
```shell
cd vllm
pip install -e .
```
3. å®‰è£… timm åº“: 
```shell
pip install timm=0.9.10
```
4. æµ‹è¯•è¿è¡Œç¤ºä¾‹ç¨‹åº:
```shell
python examples/minicpmv_example.py 
```


</details>


## å¾®è°ƒ

### ç®€æ˜“å¾®è°ƒ <!-- omit in toc -->

æˆ‘ä»¬æ”¯æŒä½¿ç”¨ Huggingface Transformers åº“ç®€æ˜“åœ°å¾®è°ƒ MiniCPM-V 2.0 å’Œ MiniCPM-Llama3-V 2.5 æ¨¡å‹ã€‚

[å‚è€ƒæ–‡æ¡£](./finetune/readme.md)

### ä½¿ç”¨ SWIFT æ¡†æ¶ <!-- omit in toc -->

æˆ‘ä»¬æ”¯æŒä½¿ç”¨ SWIFT æ¡†æ¶å¾®è°ƒ MiniCPM-V ç³»åˆ—æ¨¡å‹ã€‚SWIFT æ”¯æŒè¿‘ 200 ç§å¤§è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹å’Œéƒ¨ç½²ã€‚æ”¯æŒ PEFT æä¾›çš„è½»é‡è®­ç»ƒæ–¹æ¡ˆå’Œå®Œæ•´çš„ Adapters åº“æ”¯æŒçš„æœ€æ–°è®­ç»ƒæŠ€æœ¯å¦‚ NEFTuneã€LoRA+ã€LLaMA-PRO ç­‰ã€‚ 

å‚è€ƒæ–‡æ¡£ï¼š[MiniCPM-V 1.0](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-væœ€ä½³å®è·µ.md)ï¼Œ[MiniCPM-V 2.0](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-v-2æœ€ä½³å®è·µ.md)

## æœªæ¥è®¡åˆ’

- [x] æ”¯æŒ MiniCPM-V ç³»åˆ—æ¨¡å‹å¾®è°ƒ
- [ ] å®æ—¶å¤šæ¨¡æ€äº¤äº’ä»£ç å¼€æº



## æ¨¡å‹åè®® <!-- omit in toc -->

* æœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ [Apache-2.0](https://github.com/OpenBMB/MiniCPM/blob/main/LICENSE) åè®®å¼€æº
* MiniCPM-V æ¨¡å‹æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª [â€œMiniCPMæ¨¡å‹å•†ç”¨è®¸å¯åè®®.mdâ€](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%E6%A8%A1%E5%9E%8B%E5%95%86%E7%94%A8%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.md)ã€‚
* MiniCPM æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œåœ¨å¡«å†™[â€œé—®å·â€](https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g)è¿›è¡Œç™»è®°åäº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨ã€‚

## å£°æ˜ <!-- omit in toc -->

ä½œä¸ºå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ŒMiniCPM-V ç³»åˆ—æ¨¡å‹ï¼ˆåŒ…æ‹¬ OmniLMMï¼‰é€šè¿‡å­¦ä¹ å¤§é‡çš„å¤šæ¨¡æ€æ•°æ®æ¥ç”Ÿæˆå†…å®¹ï¼Œä½†å®ƒæ— æ³•ç†è§£ã€è¡¨è¾¾ä¸ªäººè§‚ç‚¹æˆ–ä»·å€¼åˆ¤æ–­ï¼Œå®ƒæ‰€è¾“å‡ºçš„ä»»ä½•å†…å®¹éƒ½ä¸ä»£è¡¨æ¨¡å‹å¼€å‘è€…çš„è§‚ç‚¹å’Œç«‹åœºã€‚

å› æ­¤ç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®çš„ç³»åˆ—æ¨¡å‹ç”Ÿæˆçš„å†…å®¹æ—¶ï¼Œåº”è‡ªè¡Œè´Ÿè´£å¯¹å…¶è¿›è¡Œè¯„ä¼°å’ŒéªŒè¯ã€‚å¦‚æœç”±äºä½¿ç”¨æœ¬é¡¹ç›®çš„ç³»åˆ—å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚


## æœºæ„ <!-- omit in toc -->

æœ¬é¡¹ç›®ç”±ä»¥ä¸‹æœºæ„å…±åŒå¼€å‘ï¼š

- <img src="assets/thunlp.png" width="28px"> [æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤](https://nlp.csai.tsinghua.edu.cn/)
- <img src="assets/modelbest.png" width="28px"> [é¢å£æ™ºèƒ½](https://modelbest.cn/)
- <img src="assets/zhihu.webp" width="28px"> [çŸ¥ä¹](https://www.zhihu.com/ )

## å…¶ä»–å¤šæ¨¡æ€é¡¹ç›® <!-- omit in toc -->

ğŸ‘ æ¬¢è¿äº†è§£æˆ‘ä»¬æ›´å¤šçš„å¤šæ¨¡æ€é¡¹ç›®ï¼š

[VisCPM](https://github.com/OpenBMB/VisCPM/tree/main) | [RLHF-V](https://github.com/RLHF-V/RLHF-V) | [LLaVA-UHD](https://github.com/thunlp/LLaVA-UHD) | [RLAIF-V](https://github.com/RLHF-V/RLAIF-V)

## ğŸŒŸ Star History


<table align="center">
    <p align="center">
      <img src="assets/star_history.svg"/>
    </p>
</table>

<!-- <picture>
  <source
    media="(prefers-color-scheme: dark)"
    srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-V&type=Date&theme=dark
    "
  />
  <source
    media="(prefers-color-scheme: light)"
    srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-V&type=Date
    "
  />
  <img
    alt="Star History Chart"
    src="https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-V&type=Date"
  />
</picture> -->


## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬æ¨¡å‹/ä»£ç /è®ºæ–‡æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ â­ å’Œ å¼•ç”¨ ğŸ“ï¼Œæ„Ÿè°¢ï¼

```bib
@article{yu2023rlhf,
  title={Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback},
  author={Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others},
  journal={arXiv preprint arXiv:2312.00849},
  year={2023}
}
@article{viscpm,
    title={Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages}, 
    author={Jinyi Hu and Yuan Yao and Chongyi Wang and Shan Wang and Yinxu Pan and Qianyu Chen and Tianyu Yu and Hanghao Wu and Yue Zhao and Haoye Zhang and Xu Han and Yankai Lin and Jiao Xue and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal={arXiv preprint arXiv:2308.12038},
    year={2023}
}
@article{xu2024llava-uhd,
  title={{LLaVA-UHD}: an LMM Perceiving Any Aspect Ratio and High-Resolution Images},
  author={Xu, Ruyi and Yao, Yuan and Guo, Zonghao and Cui, Junbo and Ni, Zanlin and Ge, Chunjiang and Chua, Tat-Seng and Liu, Zhiyuan and Huang, Gao},
  journal={arXiv preprint arXiv:2403.11703},
  year={2024}
}
@article{yu2024rlaifv,
  title={RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness}, 
  author={Yu, Tianyu and Zhang, Haoye and Yao, Yuan and Dang, Yunkai and Chen, Da and Lu, Xiaoman and Cui, Ganqu and He, Taiwen and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
  journal={arXiv preprint arXiv:2405.17220},
  year={2024}
}
```
